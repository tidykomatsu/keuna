{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:59:13.301072Z",
     "start_time": "2025-10-19T21:58:13.540970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import hashlib\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = r\"C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\OUTPUTS\"\n",
    "IMAGES_DIR = os.path.join(OUTPUT_DIR, \"images\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_browser_cookies():\n",
    "    \"\"\"\n",
    "    Try to get cookies from browser for authentication\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import browser_cookie3\n",
    "\n",
    "        # Try Chrome first, then Firefox\n",
    "        try:\n",
    "            cookies = browser_cookie3.chrome(domain_name=\"doctorguevara.cl\")\n",
    "            print(\"  ✓ Using Chrome cookies\")\n",
    "            return cookies\n",
    "        except:\n",
    "            try:\n",
    "                cookies = browser_cookie3.firefox(domain_name=\"doctorguevara.cl\")\n",
    "                print(\"  ✓ Using Firefox cookies\")\n",
    "                return cookies\n",
    "            except:\n",
    "                print(\"  ⚠ Could not load browser cookies\")\n",
    "                return None\n",
    "    except ImportError:\n",
    "        print(\"  ⚠ browser_cookie3 not installed. Run: pip install browser-cookie3\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def download_image(img_url, cookies=None):\n",
    "    \"\"\"\n",
    "    Download image and save it locally\n",
    "    Returns the local path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a unique filename based on URL hash\n",
    "        url_hash = hashlib.md5(img_url.encode()).hexdigest()\n",
    "\n",
    "        # Get file extension from URL\n",
    "        parsed_url = urlparse(img_url)\n",
    "        ext = os.path.splitext(parsed_url.path)[1] or \".png\"\n",
    "\n",
    "        local_filename = f\"{url_hash}{ext}\"\n",
    "        local_path = os.path.join(IMAGES_DIR, local_filename)\n",
    "\n",
    "        # Check if already downloaded\n",
    "        if os.path.exists(local_path):\n",
    "            return local_path\n",
    "\n",
    "        # Download the image\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"}\n",
    "\n",
    "        response = requests.get(img_url, headers=headers, cookies=cookies, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(local_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            return local_path\n",
    "        else:\n",
    "            print(f\"    ⚠ Failed to download image (status {response.status_code}): {img_url}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ⚠ Error downloading image: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_images_from_element(element, base_url=\"https://cursosonline.doctorguevara.cl\", cookies=None):\n",
    "    \"\"\"\n",
    "    Extract and download all images from an HTML element\n",
    "    Returns list of image info dictionaries\n",
    "    \"\"\"\n",
    "    images = []\n",
    "\n",
    "    if element:\n",
    "        img_tags = element.find_all(\"img\")\n",
    "\n",
    "        for img in img_tags:\n",
    "            img_src = img.get(\"src\", \"\")\n",
    "            img_alt = img.get(\"alt\", \"\")\n",
    "\n",
    "            if img_src:\n",
    "                # Make absolute URL\n",
    "                if img_src.startswith(\"http\"):\n",
    "                    full_url = img_src\n",
    "                else:\n",
    "                    full_url = urljoin(base_url, img_src)\n",
    "\n",
    "                # Download image\n",
    "                local_path = download_image(full_url, cookies)\n",
    "\n",
    "                images.append(\n",
    "                    {\n",
    "                        \"original_url\": full_url,\n",
    "                        \"local_path\": local_path,\n",
    "                        \"alt_text\": img_alt,\n",
    "                        \"width\": img.get(\"width\", \"\"),\n",
    "                        \"height\": img.get(\"height\", \"\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def extract_questions_from_html(html_content, source_filename, cookies=None):\n",
    "    \"\"\"\n",
    "    Extract questions from HTML content with images\n",
    "    Returns list of question dictionaries\n",
    "    \"\"\"\n",
    "    # Parse the view-source page first\n",
    "    soup_viewsource = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Check if it's a view-source format\n",
    "    line_contents = soup_viewsource.find_all(\"td\", class_=\"line-content\")\n",
    "\n",
    "    if line_contents:\n",
    "        # It's a view-source format, reconstruct HTML\n",
    "        actual_html_lines = [line_td.get_text() for line_td in line_contents]\n",
    "        actual_html = \"\\n\".join(actual_html_lines)\n",
    "        soup = BeautifulSoup(actual_html, \"html.parser\")\n",
    "    else:\n",
    "        # It's regular HTML\n",
    "        soup = soup_viewsource\n",
    "\n",
    "    # Find questions\n",
    "    questions = soup.find_all(\"div\", id=re.compile(r\"question-\\d+-\\d+\"))\n",
    "\n",
    "    if not questions:\n",
    "        # Try alternative pattern\n",
    "        questions = soup.find_all(\"div\", class_=re.compile(r\"que.*multichoice\"))\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    for idx, question in enumerate(questions, 1):\n",
    "        try:\n",
    "            # Extract question ID\n",
    "            question_id = question.get(\"id\", f\"q_{idx}\")\n",
    "\n",
    "            # Question number\n",
    "            qno_span = question.find(\"span\", class_=\"qno\")\n",
    "            q_number = qno_span.get_text(strip=True) if qno_span else str(idx)\n",
    "\n",
    "            # Question text - FULL TEXT with images\n",
    "            qtext_div = question.find(\"div\", class_=\"qtext\")\n",
    "            q_text = \"\"\n",
    "            q_images = []\n",
    "\n",
    "            if qtext_div:\n",
    "                # Extract images first\n",
    "                q_images = extract_images_from_element(qtext_div, cookies=cookies)\n",
    "\n",
    "                # Get text without images\n",
    "                qtext_copy = qtext_div.__copy__()\n",
    "                for table in qtext_copy.find_all(\"table\"):\n",
    "                    table.decompose()\n",
    "                for img in qtext_copy.find_all(\"img\"):\n",
    "                    img.decompose()\n",
    "                q_text = qtext_copy.get_text(strip=True, separator=\" \")\n",
    "\n",
    "            # Find ALL answer options\n",
    "            answer_divs = question.find_all(\"div\", class_=re.compile(r\"^r[0-1]$\"))\n",
    "\n",
    "            correct_answer = None\n",
    "            all_options = []\n",
    "\n",
    "            for ans_div in answer_divs:\n",
    "                label = ans_div.find(\"div\", class_=\"d-flex\")\n",
    "                if label:\n",
    "                    letter_span = label.find(\"span\", class_=\"answernumber\")\n",
    "                    text_div = label.find(\"div\", class_=\"flex-fill\")\n",
    "\n",
    "                    if letter_span and text_div:\n",
    "                        letter = letter_span.get_text(strip=True)\n",
    "                        text = text_div.get_text(strip=True)\n",
    "\n",
    "                        is_correct = \"correct\" in ans_div.get(\"class\", [])\n",
    "\n",
    "                        option_dict = {\"letter\": letter, \"text\": text, \"is_correct\": is_correct}\n",
    "\n",
    "                        all_options.append(option_dict)\n",
    "\n",
    "                        if is_correct:\n",
    "                            correct_answer = f\"{letter}{text}\"\n",
    "\n",
    "            # Get feedback/explanation - FULL TEXT with images\n",
    "            feedback_div = question.find(\"div\", class_=\"generalfeedback\")\n",
    "            feedback = \"\"\n",
    "            feedback_images = []\n",
    "\n",
    "            if feedback_div:\n",
    "                # Extract images from feedback\n",
    "                feedback_images = extract_images_from_element(feedback_div, cookies=cookies)\n",
    "\n",
    "                # Get text\n",
    "                feedback = feedback_div.get_text(strip=True, separator=\" \")\n",
    "\n",
    "            # Extract topic (first sentence or up to 150 chars)\n",
    "            if q_text:\n",
    "                sentences = q_text.split(\".\")\n",
    "                topic = sentences[0][:150] if sentences else q_text[:150]\n",
    "            else:\n",
    "                topic = \"Sin descripción\"\n",
    "\n",
    "            # Structure the data\n",
    "            question_data = {\n",
    "                \"question_id\": question_id,\n",
    "                \"question_number\": q_number,\n",
    "                \"source_file\": source_filename,\n",
    "                \"topic\": topic,\n",
    "                \"question_text\": q_text,\n",
    "                \"question_images\": q_images,\n",
    "                \"answer_options\": all_options,\n",
    "                \"correct_answer\": correct_answer,\n",
    "                \"explanation\": feedback,\n",
    "                \"explanation_images\": feedback_images,\n",
    "            }\n",
    "\n",
    "            extracted_data.append(question_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    ✗ Error processing question {idx}: {e}\")\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"QUIZ DATA EXTRACTOR - BATCH PROCESSOR WITH IMAGE DOWNLOAD\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Source directory: {BASE_DIR}\")\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "    print(f\"Images directory: {IMAGES_DIR}\\n\")\n",
    "\n",
    "    # Try to get browser cookies for authenticated downloads\n",
    "    print(\"Attempting to load browser cookies...\")\n",
    "    cookies = get_browser_cookies()\n",
    "    print()\n",
    "\n",
    "    # Find all HTML files\n",
    "    html_files = list(Path(BASE_DIR).glob(\"*.html\"))\n",
    "\n",
    "    if not html_files:\n",
    "        print(\"✗ No HTML files found in the directory!\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(html_files)} HTML files\\n\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Process each file\n",
    "    all_questions = []\n",
    "\n",
    "    for file_idx, html_file in enumerate(html_files, 1):\n",
    "        filename = html_file.name\n",
    "        print(f\"\\n[{file_idx}/{len(html_files)}] {filename}\")\n",
    "\n",
    "        try:\n",
    "            # Read file\n",
    "            with open(html_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                html_content = f.read()\n",
    "\n",
    "            # Extract questions\n",
    "            questions = extract_questions_from_html(html_content, filename, cookies)\n",
    "\n",
    "            if questions:\n",
    "                all_questions.extend(questions)\n",
    "\n",
    "                # Count images\n",
    "                total_images = sum(len(q[\"question_images\"]) + len(q[\"explanation_images\"]) for q in questions)\n",
    "\n",
    "                print(f\"  ✓ {len(questions)} questions, {total_images} images\")\n",
    "            else:\n",
    "                print(f\"  ⚠ No questions found\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "\n",
    "    # Generate output files\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"GENERATING OUTPUT FILES\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    if not all_questions:\n",
    "        print(\"✗ No questions were extracted!\")\n",
    "        return\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 1. Save complete JSON with all data\n",
    "    output_json = os.path.join(OUTPUT_DIR, f\"questions_complete_{timestamp}.json\")\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_questions, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✓ Saved JSON: {os.path.basename(output_json)}\")\n",
    "\n",
    "    # 2. Create simplified DataFrame for Excel/CSV\n",
    "    simplified_data = []\n",
    "    for q in all_questions:\n",
    "        row = {\n",
    "            \"question_id\": q[\"question_id\"],\n",
    "            \"question_number\": q[\"question_number\"],\n",
    "            \"source_file\": q[\"source_file\"],\n",
    "            \"topic\": q[\"topic\"],\n",
    "            \"question_text\": q[\"question_text\"],\n",
    "            \"has_question_images\": len(q[\"question_images\"]) > 0,\n",
    "            \"question_image_count\": len(q[\"question_images\"]),\n",
    "            \"question_image_paths\": \" | \".join(\n",
    "                [img[\"local_path\"] or img[\"original_url\"] for img in q[\"question_images\"]]\n",
    "            ),\n",
    "            \"correct_answer\": q[\"correct_answer\"],\n",
    "            \"explanation\": q[\"explanation\"],\n",
    "            \"has_explanation_images\": len(q[\"explanation_images\"]) > 0,\n",
    "            \"explanation_image_count\": len(q[\"explanation_images\"]),\n",
    "            \"explanation_image_paths\": \" | \".join(\n",
    "                [img[\"local_path\"] or img[\"original_url\"] for img in q[\"explanation_images\"]]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        # Add answer options\n",
    "        for i, opt in enumerate(q[\"answer_options\"], 1):\n",
    "            row[f\"option_{i}\"] = f\"{opt['letter']}{opt['text']}\"\n",
    "            row[f\"option_{i}_correct\"] = opt[\"is_correct\"]\n",
    "\n",
    "        simplified_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(simplified_data)\n",
    "\n",
    "    # Save Excel\n",
    "    output_excel = os.path.join(OUTPUT_DIR, f\"questions_database_{timestamp}.xlsx\")\n",
    "    df.to_excel(output_excel, index=False, engine=\"openpyxl\")\n",
    "    print(f\"✓ Saved Excel: {os.path.basename(output_excel)}\")\n",
    "\n",
    "    # Save CSV\n",
    "    output_csv = os.path.join(OUTPUT_DIR, f\"questions_database_{timestamp}.csv\")\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✓ Saved CSV: {os.path.basename(output_csv)}\")\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Files processed: {len(html_files)}\")\n",
    "    print(f\"Total questions: {len(all_questions)}\")\n",
    "\n",
    "    total_q_images = sum(len(q[\"question_images\"]) for q in all_questions)\n",
    "    total_e_images = sum(len(q[\"explanation_images\"]) for q in all_questions)\n",
    "    total_images = total_q_images + total_e_images\n",
    "\n",
    "    print(f\"Total images: {total_images}\")\n",
    "    print(f\"  - In questions: {total_q_images}\")\n",
    "    print(f\"  - In explanations: {total_e_images}\")\n",
    "\n",
    "    downloaded_images = sum(\n",
    "        1 for q in all_questions for img in q[\"question_images\"] + q[\"explanation_images\"] if img[\"local_path\"]\n",
    "    )\n",
    "    print(f\"Successfully downloaded: {downloaded_images}/{total_images}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "90bbcc15d032b852",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUIZ DATA EXTRACTOR - BATCH PROCESSOR WITH IMAGE DOWNLOAD\n",
      "================================================================================\n",
      "Source directory: C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\n",
      "Output directory: C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\OUTPUTS\n",
      "Images directory: C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\OUTPUTS\\images\n",
      "\n",
      "Attempting to load browser cookies...\n",
      "  ⚠ browser_cookie3 not installed. Run: pip install browser-cookie3\n",
      "\n",
      "Found 70 HTML files\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[1/70] 1.1 Cuestionario Diabetes.html\n",
      "  ✓ 15 questions, 0 images\n",
      "\n",
      "[2/70] 1.2. Cuestionario Diabetes.html\n",
      "  ✓ 15 questions, 0 images\n",
      "\n",
      "[3/70] 1.3 Cuestionario Diabetes.html\n",
      "  ✓ 14 questions, 0 images\n",
      "\n",
      "[4/70] 10.2 Cuestionario Neurología.html\n",
      "  ✓ 14 questions, 0 images\n",
      "\n",
      "[5/70] 10.3 Cuestionario Neurología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[6/70] 10.4 Cuestionario Neurología.html\n",
      "  ✓ 14 questions, 0 images\n",
      "\n",
      "[7/70] 10.5 Cuestionario Neurología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[8/70] 10.6 Cuestionario Neurología.html\n",
      "  ✓ 7 questions, 1 images\n",
      "\n",
      "[9/70] 2.1 Cuestionario Endocrinología.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[10/70] 2.2 Cuestionario Endocrinología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[11/70] 2.3 Cuestionario Endocrinología.html\n",
      "  ✓ 13 questions, 0 images\n",
      "\n",
      "[12/70] 2.4 Cuestionario Endocrinología.html\n",
      "  ✓ 14 questions, 0 images\n",
      "\n",
      "[13/70] 2.5 Cuestionario Endocrinología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[14/70] 2.6 Cuestionario Endocrinología.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[15/70] 2.7 Cuestionario Endocrinología.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[16/70] 2.8 Cuestionario Endocrinología.html\n",
      "  ✓ 6 questions, 0 images\n",
      "\n",
      "[17/70] 3.1 Cuestionario Cardiología.html\n",
      "  ✓ 20 questions, 2 images\n",
      "\n",
      "[18/70] 3.2 Cuestionario Cardiología.html\n",
      "  ✓ 20 questions, 3 images\n",
      "\n",
      "[19/70] 3.3 Cuestionario Cardiología.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[20/70] 3.4 Cuestionario Cardiología.html\n",
      "  ✓ 20 questions, 1 images\n",
      "\n",
      "[21/70] 3.5 Cuestionario Cardiología.html\n",
      "  ✓ 20 questions, 4 images\n",
      "\n",
      "[22/70] 3.6 Cuestionario Cardiología.html\n",
      "  ✓ 13 questions, 3 images\n",
      "\n",
      "[23/70] 3.7 Cuestionario Cardiología.html\n",
      "  ✓ 15 questions, 15 images\n",
      "\n",
      "[24/70] 4.1 Cuestionario Nefrología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[25/70] 4.2 Cuestionario Nefrología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[26/70] 4.3 Cuestionario Nefrología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[27/70] 4.4 Cuestionario Nefrología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[28/70] 4.5 Cuestionario Nefrología.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[29/70] 4.6 Cuestionario Nefrología.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[30/70] 4.7 Cuestionario Nefrología.html\n",
      "  ✓ 10 questions, 1 images\n",
      "\n",
      "[31/70] 4.8 Cuestionario Nefrología.html\n",
      "  ✓ 7 questions, 1 images\n",
      "\n",
      "[32/70] 5.1 Cuestionario Reumatología.html\n",
      "  ✓ 20 questions, 4 images\n",
      "\n",
      "[33/70] 5.2 Cuestionario Reumatología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[34/70] 5.3 Cuestionario Reumatología.html\n",
      "  ✓ 10 questions, 1 images\n",
      "\n",
      "[35/70] 5.4 Cuestionario Reumatología.html\n",
      "  ✓ 7 questions, 0 images\n",
      "\n",
      "[36/70] 6.1 Cuestionario Hematología.html\n",
      "  ✓ 20 questions, 1 images\n",
      "\n",
      "[37/70] 6.2 Cuestionario Hematología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[38/70] 6.3 Cuestionario Hematología.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[39/70] 6.4 Cuestionario Hematología.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[40/70] 6.5 Cuestionario Hematología.html\n",
      "  ✓ 10 questions, 2 images\n",
      "\n",
      "[41/70] 6.6 Cuestionario Hematología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[42/70] 6.7 Cuestionario Hematología.html\n",
      "  ✓ 7 questions, 0 images\n",
      "\n",
      "[43/70] 7.1 Cuestionario Infectología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[44/70] 7.2 Cuestionario Infectología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[45/70] 7.3 Cuestionario Infectología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[46/70] 7.4 Cuestionario Infectología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[47/70] 7.5 Cuestionario Infectología.html\n",
      "  ✓ 20 questions, 1 images\n",
      "\n",
      "[48/70] 7.6 Cuestionario Infectología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[49/70] 7.7 Cuestionario Infectología.html\n",
      "  ✓ 11 questions, 0 images\n",
      "\n",
      "[50/70] 7.8 Cuestionario Infectología.html\n",
      "  ✓ 4 questions, 1 images\n",
      "\n",
      "[51/70] 8.1 Cuestionario Respiratorio.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[52/70] 8.2 Cuestionario Respiratorio.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[53/70] 8.3 Cuestionario Respiratorio.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[54/70] 8.4 Cuestionario Respiratorio.html\n",
      "  ✓ 20 questions, 2 images\n",
      "\n",
      "[55/70] 8.5 Cuestionario Respiratorio.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[56/70] 8.6 Cuestionario Respiratorio.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[57/70] 8.7 Cuestionario Respiratorio.html\n",
      "  ✓ 9 questions, 4 images\n",
      "\n",
      "[58/70] 9.1 Cuestionario Gastroenterología.html\n",
      "    ⚠ Failed to download image (status 403): https://www.researchgate.net/publication/286484630/figure/fig1/AS:357266189504522@1462190305900/Rumack-Matthew-nomogram-modified-after-11.png\n",
      "  ✓ 10 questions, 1 images\n",
      "\n",
      "[59/70] 9.2 Cuestionario Gastroenterología.html\n",
      "  ✓ 20 questions, 1 images\n",
      "\n",
      "[60/70] 9.3 Cuestionario Gastroenterología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[61/70] 9.4 Cuestionario Gastroenterología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[62/70] 9.5 Cuestionario Gastroenterología.html\n",
      "  ✓ 20 questions, 0 images\n",
      "\n",
      "[63/70] 9.6. Cuestionario Gastroenterología.html\n",
      "  ✓ 10 questions, 1 images\n",
      "\n",
      "[64/70] Prueba repaso 1.html\n",
      "  ✓ 7 questions, 0 images\n",
      "\n",
      "[65/70] Prueba repaso 2.html\n",
      "  ✓ 7 questions, 2 images\n",
      "\n",
      "[66/70] Prueba repaso 3.html\n",
      "  ✓ 7 questions, 1 images\n",
      "\n",
      "[67/70] Prueba repaso 4.html\n",
      "  ✓ 10 questions, 3 images\n",
      "\n",
      "[68/70] Prueba repaso 5.html\n",
      "  ✓ 5 questions, 2 images\n",
      "\n",
      "[69/70] Reconstrucción Eunacom julio 2024 P1.html\n",
      "  ✓ 10 questions, 0 images\n",
      "\n",
      "[70/70] Reconstrucción Eunacom julio 2024 P2.html\n",
      "  ✓ 10 questions, 1 images\n",
      "\n",
      "================================================================================\n",
      "GENERATING OUTPUT FILES\n",
      "================================================================================\n",
      "\n",
      "✓ Saved JSON: questions_complete_20251019_185913.json\n",
      "✓ Saved Excel: questions_database_20251019_185913.xlsx\n",
      "✓ Saved CSV: questions_database_20251019_185913.csv\n",
      "\n",
      "================================================================================\n",
      "STATISTICS\n",
      "================================================================================\n",
      "Files processed: 70\n",
      "Total questions: 1021\n",
      "Total images: 59\n",
      "  - In questions: 52\n",
      "  - In explanations: 7\n",
      "Successfully downloaded: 58/59\n",
      "\n",
      "================================================================================\n",
      "COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "questions_database_20251019_185913.xlsx",
   "id": "14a6282001a7ecf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T22:32:51.517255Z",
     "start_time": "2025-10-19T22:32:51.433383Z"
    }
   },
   "cell_type": "code",
   "source": "import polars as pl",
   "id": "1c9ed25cecd691cf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T22:33:46.687073Z",
     "start_time": "2025-10-19T22:33:46.680867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pl.read_csv(r\"C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\OUTPUTS\\questions_database_20251019_185913.csv\")[\n",
    "    \"source_file\"\n",
    "].unique().to_list()"
   ],
   "id": "6b1d39639be7aa85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7.2 Cuestionario Infectología.html',\n",
       " '1.2. Cuestionario Diabetes.html',\n",
       " 'Prueba repaso 4.html',\n",
       " '2.2 Cuestionario Endocrinología.html',\n",
       " '3.6 Cuestionario Cardiología.html',\n",
       " '7.1 Cuestionario Infectología.html',\n",
       " '5.1 Cuestionario Reumatología.html',\n",
       " '8.4 Cuestionario Respiratorio.html',\n",
       " '2.3 Cuestionario Endocrinología.html',\n",
       " '4.5 Cuestionario Nefrología.html',\n",
       " 'Reconstrucción Eunacom julio 2024 P2.html',\n",
       " '10.3 Cuestionario Neurología.html',\n",
       " '4.2 Cuestionario Nefrología.html',\n",
       " '9.1 Cuestionario Gastroenterología.html',\n",
       " '5.4 Cuestionario Reumatología.html',\n",
       " '2.1 Cuestionario Endocrinología.html',\n",
       " '6.1 Cuestionario Hematología.html',\n",
       " '6.6 Cuestionario Hematología.html',\n",
       " '8.7 Cuestionario Respiratorio.html',\n",
       " '1.3 Cuestionario Diabetes.html',\n",
       " '3.2 Cuestionario Cardiología.html',\n",
       " '2.4 Cuestionario Endocrinología.html',\n",
       " '9.4 Cuestionario Gastroenterología.html',\n",
       " '6.5 Cuestionario Hematología.html',\n",
       " '10.4 Cuestionario Neurología.html',\n",
       " '6.3 Cuestionario Hematología.html',\n",
       " '2.5 Cuestionario Endocrinología.html',\n",
       " '1.1 Cuestionario Diabetes.html',\n",
       " '3.4 Cuestionario Cardiología.html',\n",
       " 'Prueba repaso 1.html',\n",
       " '3.5 Cuestionario Cardiología.html',\n",
       " '2.6 Cuestionario Endocrinología.html',\n",
       " '2.8 Cuestionario Endocrinología.html',\n",
       " '10.6 Cuestionario Neurología.html',\n",
       " '4.4 Cuestionario Nefrología.html',\n",
       " '9.5 Cuestionario Gastroenterología.html',\n",
       " '9.6. Cuestionario Gastroenterología.html',\n",
       " '7.3 Cuestionario Infectología.html',\n",
       " '4.3 Cuestionario Nefrología.html',\n",
       " '4.6 Cuestionario Nefrología.html',\n",
       " '8.5 Cuestionario Respiratorio.html',\n",
       " '8.2 Cuestionario Respiratorio.html',\n",
       " '9.2 Cuestionario Gastroenterología.html',\n",
       " '7.7 Cuestionario Infectología.html',\n",
       " '7.4 Cuestionario Infectología.html',\n",
       " '10.2 Cuestionario Neurología.html',\n",
       " '4.1 Cuestionario Nefrología.html',\n",
       " '4.7 Cuestionario Nefrología.html',\n",
       " '5.2 Cuestionario Reumatología.html',\n",
       " 'Reconstrucción Eunacom julio 2024 P1.html',\n",
       " '4.8 Cuestionario Nefrología.html',\n",
       " '8.6 Cuestionario Respiratorio.html',\n",
       " '2.7 Cuestionario Endocrinología.html',\n",
       " '10.5 Cuestionario Neurología.html',\n",
       " '7.5 Cuestionario Infectología.html',\n",
       " 'Prueba repaso 3.html',\n",
       " '7.6 Cuestionario Infectología.html',\n",
       " '7.8 Cuestionario Infectología.html',\n",
       " 'Prueba repaso 5.html',\n",
       " '6.4 Cuestionario Hematología.html',\n",
       " 'Prueba repaso 2.html',\n",
       " '9.3 Cuestionario Gastroenterología.html',\n",
       " '8.1 Cuestionario Respiratorio.html',\n",
       " '3.7 Cuestionario Cardiología.html',\n",
       " '6.7 Cuestionario Hematología.html',\n",
       " '3.3 Cuestionario Cardiología.html',\n",
       " '5.3 Cuestionario Reumatología.html',\n",
       " '6.2 Cuestionario Hematología.html',\n",
       " '8.3 Cuestionario Respiratorio.html',\n",
       " '3.1 Cuestionario Cardiología.html']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a90479b161ede400"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e84363256e2d79c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4ca99d2b79a579f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:45:51.154276Z",
     "start_time": "2025-10-19T21:45:17.058150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = r\"C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\"\n",
    "OUTPUT_DIR = BASE_DIR  # Save outputs in the same directory\n",
    "\n",
    "\n",
    "def extract_questions_from_html(html_content, source_filename):\n",
    "    \"\"\"\n",
    "    Extract questions from HTML content\n",
    "    Returns list of question dictionaries\n",
    "    \"\"\"\n",
    "    # Parse the view-source page first\n",
    "    soup_viewsource = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Check if it's a view-source format\n",
    "    line_contents = soup_viewsource.find_all(\"td\", class_=\"line-content\")\n",
    "\n",
    "    if line_contents:\n",
    "        # It's a view-source format, reconstruct HTML\n",
    "        actual_html_lines = [line_td.get_text() for line_td in line_contents]\n",
    "        actual_html = \"\\n\".join(actual_html_lines)\n",
    "        soup = BeautifulSoup(actual_html, \"html.parser\")\n",
    "    else:\n",
    "        # It's regular HTML\n",
    "        soup = soup_viewsource\n",
    "\n",
    "    # Find questions\n",
    "    questions = soup.find_all(\"div\", id=re.compile(r\"question-\\d+-\\d+\"))\n",
    "\n",
    "    if not questions:\n",
    "        # Try alternative pattern\n",
    "        questions = soup.find_all(\"div\", class_=re.compile(r\"que.*multichoice\"))\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    for idx, question in enumerate(questions, 1):\n",
    "        try:\n",
    "            # Extract question ID from the div id attribute\n",
    "            question_id = question.get(\"id\", f\"q_{idx}\")\n",
    "\n",
    "            # Question number\n",
    "            qno_span = question.find(\"span\", class_=\"qno\")\n",
    "            q_number = qno_span.get_text(strip=True) if qno_span else str(idx)\n",
    "\n",
    "            # Question text - FULL TEXT\n",
    "            qtext_div = question.find(\"div\", class_=\"qtext\")\n",
    "            if qtext_div:\n",
    "                qtext_copy = qtext_div.__copy__()\n",
    "                # Remove tables but keep the rest\n",
    "                for table in qtext_copy.find_all(\"table\"):\n",
    "                    table.decompose()\n",
    "                q_text = qtext_copy.get_text(strip=True, separator=\" \")\n",
    "            else:\n",
    "                q_text = \"\"\n",
    "\n",
    "            # Find ALL answer options\n",
    "            answer_divs = question.find_all(\"div\", class_=re.compile(r\"^r[0-1]$\"))\n",
    "\n",
    "            correct_answer = None\n",
    "            all_options = []\n",
    "\n",
    "            for ans_div in answer_divs:\n",
    "                label = ans_div.find(\"div\", class_=\"d-flex\")\n",
    "                if label:\n",
    "                    letter_span = label.find(\"span\", class_=\"answernumber\")\n",
    "                    text_div = label.find(\"div\", class_=\"flex-fill\")\n",
    "\n",
    "                    if letter_span and text_div:\n",
    "                        letter = letter_span.get_text(strip=True)\n",
    "                        text = text_div.get_text(strip=True)\n",
    "\n",
    "                        is_correct = \"correct\" in ans_div.get(\"class\", [])\n",
    "\n",
    "                        option_dict = {\"letter\": letter, \"text\": text, \"is_correct\": is_correct}\n",
    "\n",
    "                        all_options.append(option_dict)\n",
    "\n",
    "                        if is_correct:\n",
    "                            correct_answer = f\"{letter} {text}\"\n",
    "\n",
    "            # Get feedback/explanation - FULL TEXT\n",
    "            feedback_div = question.find(\"div\", class_=\"generalfeedback\")\n",
    "            feedback = feedback_div.get_text(strip=True, separator=\" \") if feedback_div else \"\"\n",
    "\n",
    "            # Get the \"correct answer\" text\n",
    "            rightanswer_div = question.find(\"div\", class_=\"rightanswer\")\n",
    "            right_answer_text = rightanswer_div.get_text(strip=True) if rightanswer_div else \"\"\n",
    "\n",
    "            # Extract topic (first 100 chars of question or first sentence)\n",
    "            topic = q_text.split(\".\")[0][:100] if q_text else \"Tema no especificado\"\n",
    "\n",
    "            # Structure the data\n",
    "            question_data = {\n",
    "                \"question_id\": question_id,\n",
    "                \"question_number\": q_number,\n",
    "                \"topic\": topic,\n",
    "                \"question_text\": q_text,\n",
    "                \"answer_options\": all_options,\n",
    "                \"correct_answer\": correct_answer,\n",
    "                \"explanation\": feedback,\n",
    "                \"right_answer_text\": right_answer_text,\n",
    "                \"source_file\": source_filename,\n",
    "            }\n",
    "\n",
    "            extracted_data.append(question_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    ✗ Error processing question {idx} in {source_filename}: {e}\")\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"QUIZ DATA EXTRACTOR - BATCH PROCESSOR\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Source directory: {BASE_DIR}\\n\")\n",
    "\n",
    "    # Find all HTML files\n",
    "    html_files = list(Path(BASE_DIR).glob(\"*.html\"))\n",
    "\n",
    "    if not html_files:\n",
    "        print(\"✗ No HTML files found in the directory!\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(html_files)} HTML files\\n\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Process each file\n",
    "    all_questions = []\n",
    "    file_stats = []\n",
    "\n",
    "    for file_idx, html_file in enumerate(html_files, 1):\n",
    "        filename = html_file.name\n",
    "        print(f\"\\n[{file_idx}/{len(html_files)}] Processing: {filename}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        try:\n",
    "            # Read file\n",
    "            with open(html_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                html_content = f.read()\n",
    "\n",
    "            print(f\"  File size: {len(html_content):,} characters\")\n",
    "\n",
    "            # Extract questions\n",
    "            questions = extract_questions_from_html(html_content, filename)\n",
    "\n",
    "            if questions:\n",
    "                all_questions.extend(questions)\n",
    "                print(f\"  ✓ Extracted {len(questions)} questions\")\n",
    "\n",
    "                file_stats.append({\"filename\": filename, \"questions_count\": len(questions), \"status\": \"Success\"})\n",
    "            else:\n",
    "                print(f\"  ⚠ No questions found\")\n",
    "                file_stats.append({\"filename\": filename, \"questions_count\": 0, \"status\": \"No questions found\"})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error processing file: {e}\")\n",
    "            file_stats.append({\"filename\": filename, \"questions_count\": 0, \"status\": f\"Error: {str(e)[:50]}\"})\n",
    "\n",
    "    # Generate output files\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"GENERATING OUTPUT FILES\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    if not all_questions:\n",
    "        print(\"✗ No questions were extracted from any file!\")\n",
    "        return\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 1. Save as JSON\n",
    "    output_json = os.path.join(OUTPUT_DIR, f\"quiz_data_consolidated_{timestamp}.json\")\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_questions, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✓ Saved JSON: {output_json}\")\n",
    "\n",
    "    # 2. Create flattened DataFrame for Excel/CSV\n",
    "    flattened_data = []\n",
    "    for q in all_questions:\n",
    "        row = {\n",
    "            \"question_id\": q[\"question_id\"],\n",
    "            \"question_number\": q[\"question_number\"],\n",
    "            \"topic\": q[\"topic\"],\n",
    "            \"question_text\": q[\"question_text\"],\n",
    "            \"correct_answer\": q[\"correct_answer\"],\n",
    "            \"explanation\": q[\"explanation\"],\n",
    "            \"source_file\": q[\"source_file\"],\n",
    "        }\n",
    "\n",
    "        # Add each answer option as columns\n",
    "        for i, opt in enumerate(q[\"answer_options\"], 1):\n",
    "            row[f\"option_{i}\"] = f\"{opt['letter']} {opt['text']}\"\n",
    "            row[f\"option_{i}_correct\"] = \"SÍ\" if opt[\"is_correct\"] else \"NO\"\n",
    "\n",
    "        flattened_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "\n",
    "    # Save Excel\n",
    "    output_excel = os.path.join(OUTPUT_DIR, f\"quiz_data_consolidated_{timestamp}.xlsx\")\n",
    "    df.to_excel(output_excel, index=False, engine=\"openpyxl\")\n",
    "    print(f\"✓ Saved Excel: {output_excel}\")\n",
    "\n",
    "    # Save CSV\n",
    "    output_csv = os.path.join(OUTPUT_DIR, f\"quiz_data_consolidated_{timestamp}.csv\")\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✓ Saved CSV: {output_csv}\")\n",
    "\n",
    "    # 3. Save processing summary\n",
    "    summary_df = pd.DataFrame(file_stats)\n",
    "    summary_file = os.path.join(OUTPUT_DIR, f\"processing_summary_{timestamp}.csv\")\n",
    "    summary_df.to_csv(summary_file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✓ Saved processing summary: {summary_file}\")\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nFiles processed: {len(html_files)}\")\n",
    "    print(f\"Total questions extracted: {len(all_questions)}\")\n",
    "    print(f\"Successful files: {len([s for s in file_stats if s['status'] == 'Success'])}\")\n",
    "    print(f\"Failed files: {len([s for s in file_stats if s['status'] != 'Success'])}\")\n",
    "\n",
    "    print(\"\\n\" + \"Per-file breakdown:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    if all_questions:\n",
    "        avg_options = sum(len(q[\"answer_options\"]) for q in all_questions) / len(all_questions)\n",
    "        print(f\"\\nAverage options per question: {avg_options:.1f}\")\n",
    "\n",
    "        # Count questions by source file\n",
    "        print(\"\\nQuestions per file:\")\n",
    "        source_counts = {}\n",
    "        for q in all_questions:\n",
    "            source = q[\"source_file\"]\n",
    "            source_counts[source] = source_counts.get(source, 0) + 1\n",
    "\n",
    "        for source, count in sorted(source_counts.items()):\n",
    "            print(f\"  {source}: {count} questions\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "b105e969728343c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUIZ DATA EXTRACTOR - BATCH PROCESSOR\n",
      "================================================================================\n",
      "Source directory: C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\n",
      "\n",
      "Found 70 HTML files\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[1/70] Processing: 1.1 Cuestionario Diabetes.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,074,933 characters\n",
      "  ✓ Extracted 15 questions\n",
      "\n",
      "[2/70] Processing: 1.2. Cuestionario Diabetes.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,056,766 characters\n",
      "  ✓ Extracted 15 questions\n",
      "\n",
      "[3/70] Processing: 1.3 Cuestionario Diabetes.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,026,345 characters\n",
      "  ✓ Extracted 14 questions\n",
      "\n",
      "[4/70] Processing: 10.2 Cuestionario Neurología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,025,094 characters\n",
      "  ✓ Extracted 14 questions\n",
      "\n",
      "[5/70] Processing: 10.3 Cuestionario Neurología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,145,674 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[6/70] Processing: 10.4 Cuestionario Neurología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,026,224 characters\n",
      "  ✓ Extracted 14 questions\n",
      "\n",
      "[7/70] Processing: 10.5 Cuestionario Neurología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,149,820 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[8/70] Processing: 10.6 Cuestionario Neurología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 894,018 characters\n",
      "  ✓ Extracted 7 questions\n",
      "\n",
      "[9/70] Processing: 2.1 Cuestionario Endocrinología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 952,498 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[10/70] Processing: 2.2 Cuestionario Endocrinología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,150,230 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[11/70] Processing: 2.3 Cuestionario Endocrinología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,004,176 characters\n",
      "  ✓ Extracted 13 questions\n",
      "\n",
      "[12/70] Processing: 2.4 Cuestionario Endocrinología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,027,567 characters\n",
      "  ✓ Extracted 14 questions\n",
      "\n",
      "[13/70] Processing: 2.5 Cuestionario Endocrinología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,141,122 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[14/70] Processing: 2.6 Cuestionario Endocrinología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 947,676 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[15/70] Processing: 2.7 Cuestionario Endocrinología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 945,361 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[16/70] Processing: 2.8 Cuestionario Endocrinología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 872,313 characters\n",
      "  ✓ Extracted 6 questions\n",
      "\n",
      "[17/70] Processing: 3.1 Cuestionario Cardiología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,149,220 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[18/70] Processing: 3.2 Cuestionario Cardiología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,155,150 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[19/70] Processing: 3.3 Cuestionario Cardiología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 952,633 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[20/70] Processing: 3.4 Cuestionario Cardiología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,150,882 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[21/70] Processing: 3.5 Cuestionario Cardiología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,151,249 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[22/70] Processing: 3.6 Cuestionario Cardiología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,013,212 characters\n",
      "  ✓ Extracted 13 questions\n",
      "\n",
      "[23/70] Processing: 3.7 Cuestionario Cardiología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,046,551 characters\n",
      "  ✓ Extracted 15 questions\n",
      "\n",
      "[24/70] Processing: 4.1 Cuestionario Nefrología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,157,717 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[25/70] Processing: 4.2 Cuestionario Nefrología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,151,189 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[26/70] Processing: 4.3 Cuestionario Nefrología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,147,214 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[27/70] Processing: 4.4 Cuestionario Nefrología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,144,976 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[28/70] Processing: 4.5 Cuestionario Nefrología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 952,018 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[29/70] Processing: 4.6 Cuestionario Nefrología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 949,808 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[30/70] Processing: 4.7 Cuestionario Nefrología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 953,214 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[31/70] Processing: 4.8 Cuestionario Nefrología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 889,750 characters\n",
      "  ✓ Extracted 7 questions\n",
      "\n",
      "[32/70] Processing: 5.1 Cuestionario Reumatología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,156,442 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[33/70] Processing: 5.2 Cuestionario Reumatología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,146,196 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[34/70] Processing: 5.3 Cuestionario Reumatología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 950,810 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[35/70] Processing: 5.4 Cuestionario Reumatología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 889,652 characters\n",
      "  ✓ Extracted 7 questions\n",
      "\n",
      "[36/70] Processing: 6.1 Cuestionario Hematología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,147,303 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[37/70] Processing: 6.2 Cuestionario Hematología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,143,943 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[38/70] Processing: 6.3 Cuestionario Hematología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 950,338 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[39/70] Processing: 6.4 Cuestionario Hematología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 949,849 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[40/70] Processing: 6.5 Cuestionario Hematología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 950,362 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[41/70] Processing: 6.6 Cuestionario Hematología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,143,013 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[42/70] Processing: 6.7 Cuestionario Hematología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 889,525 characters\n",
      "  ✓ Extracted 7 questions\n",
      "\n",
      "[43/70] Processing: 7.1 Cuestionario Infectología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,145,350 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[44/70] Processing: 7.2 Cuestionario Infectología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,145,900 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[45/70] Processing: 7.3 Cuestionario Infectología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,139,624 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[46/70] Processing: 7.4 Cuestionario Infectología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,143,030 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[47/70] Processing: 7.5 Cuestionario Infectología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,143,855 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[48/70] Processing: 7.6 Cuestionario Infectología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,143,841 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[49/70] Processing: 7.7 Cuestionario Infectología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 967,307 characters\n",
      "  ✓ Extracted 11 questions\n",
      "\n",
      "[50/70] Processing: 7.8 Cuestionario Infectología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 833,904 characters\n",
      "  ✓ Extracted 4 questions\n",
      "\n",
      "[51/70] Processing: 8.1 Cuestionario Respiratorio.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,151,795 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[52/70] Processing: 8.2 Cuestionario Respiratorio.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,148,816 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[53/70] Processing: 8.3 Cuestionario Respiratorio.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,145,384 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[54/70] Processing: 8.4 Cuestionario Respiratorio.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,149,657 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[55/70] Processing: 8.5 Cuestionario Respiratorio.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,145,929 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[56/70] Processing: 8.6 Cuestionario Respiratorio.html\n",
      "------------------------------------------------------------\n",
      "  File size: 948,280 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[57/70] Processing: 8.7 Cuestionario Respiratorio.html\n",
      "------------------------------------------------------------\n",
      "  File size: 932,683 characters\n",
      "  ✓ Extracted 9 questions\n",
      "\n",
      "[58/70] Processing: 9.1 Cuestionario Gastroenterología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 954,411 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[59/70] Processing: 9.2 Cuestionario Gastroenterología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,150,078 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[60/70] Processing: 9.3 Cuestionario Gastroenterología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,143,564 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[61/70] Processing: 9.4 Cuestionario Gastroenterología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,146,354 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[62/70] Processing: 9.5 Cuestionario Gastroenterología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,147,955 characters\n",
      "  ✓ Extracted 20 questions\n",
      "\n",
      "[63/70] Processing: 9.6. Cuestionario Gastroenterología.html\n",
      "------------------------------------------------------------\n",
      "  File size: 950,540 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[64/70] Processing: Prueba repaso 1.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,004,830 characters\n",
      "  ✓ Extracted 7 questions\n",
      "\n",
      "[65/70] Processing: Prueba repaso 2.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,008,711 characters\n",
      "  ✓ Extracted 7 questions\n",
      "\n",
      "[66/70] Processing: Prueba repaso 3.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,013,059 characters\n",
      "  ✓ Extracted 7 questions\n",
      "\n",
      "[67/70] Processing: Prueba repaso 4.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,059,920 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[68/70] Processing: Prueba repaso 5.html\n",
      "------------------------------------------------------------\n",
      "  File size: 990,461 characters\n",
      "  ✓ Extracted 5 questions\n",
      "\n",
      "[69/70] Processing: Reconstrucción Eunacom julio 2024 P1.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,095,199 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "[70/70] Processing: Reconstrucción Eunacom julio 2024 P2.html\n",
      "------------------------------------------------------------\n",
      "  File size: 1,098,052 characters\n",
      "  ✓ Extracted 10 questions\n",
      "\n",
      "================================================================================\n",
      "GENERATING OUTPUT FILES\n",
      "================================================================================\n",
      "\n",
      "✓ Saved JSON: C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\\quiz_data_consolidated_20251019_184550.json\n",
      "✓ Saved Excel: C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\\quiz_data_consolidated_20251019_184550.xlsx\n",
      "✓ Saved CSV: C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\\quiz_data_consolidated_20251019_184550.csv\n",
      "✓ Saved processing summary: C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\\processing_summary_20251019_184550.csv\n",
      "\n",
      "================================================================================\n",
      "FINAL STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Files processed: 70\n",
      "Total questions extracted: 1021\n",
      "Successful files: 70\n",
      "Failed files: 0\n",
      "\n",
      "Per-file breakdown:\n",
      "                                 filename  questions_count  status\n",
      "           1.1 Cuestionario Diabetes.html               15 Success\n",
      "          1.2. Cuestionario Diabetes.html               15 Success\n",
      "           1.3 Cuestionario Diabetes.html               14 Success\n",
      "        10.2 Cuestionario Neurología.html               14 Success\n",
      "        10.3 Cuestionario Neurología.html               20 Success\n",
      "        10.4 Cuestionario Neurología.html               14 Success\n",
      "        10.5 Cuestionario Neurología.html               20 Success\n",
      "        10.6 Cuestionario Neurología.html                7 Success\n",
      "     2.1 Cuestionario Endocrinología.html               10 Success\n",
      "     2.2 Cuestionario Endocrinología.html               20 Success\n",
      "     2.3 Cuestionario Endocrinología.html               13 Success\n",
      "     2.4 Cuestionario Endocrinología.html               14 Success\n",
      "     2.5 Cuestionario Endocrinología.html               20 Success\n",
      "     2.6 Cuestionario Endocrinología.html               10 Success\n",
      "     2.7 Cuestionario Endocrinología.html               10 Success\n",
      "     2.8 Cuestionario Endocrinología.html                6 Success\n",
      "        3.1 Cuestionario Cardiología.html               20 Success\n",
      "        3.2 Cuestionario Cardiología.html               20 Success\n",
      "        3.3 Cuestionario Cardiología.html               10 Success\n",
      "        3.4 Cuestionario Cardiología.html               20 Success\n",
      "        3.5 Cuestionario Cardiología.html               20 Success\n",
      "        3.6 Cuestionario Cardiología.html               13 Success\n",
      "        3.7 Cuestionario Cardiología.html               15 Success\n",
      "         4.1 Cuestionario Nefrología.html               20 Success\n",
      "         4.2 Cuestionario Nefrología.html               20 Success\n",
      "         4.3 Cuestionario Nefrología.html               20 Success\n",
      "         4.4 Cuestionario Nefrología.html               20 Success\n",
      "         4.5 Cuestionario Nefrología.html               10 Success\n",
      "         4.6 Cuestionario Nefrología.html               10 Success\n",
      "         4.7 Cuestionario Nefrología.html               10 Success\n",
      "         4.8 Cuestionario Nefrología.html                7 Success\n",
      "       5.1 Cuestionario Reumatología.html               20 Success\n",
      "       5.2 Cuestionario Reumatología.html               20 Success\n",
      "       5.3 Cuestionario Reumatología.html               10 Success\n",
      "       5.4 Cuestionario Reumatología.html                7 Success\n",
      "        6.1 Cuestionario Hematología.html               20 Success\n",
      "        6.2 Cuestionario Hematología.html               20 Success\n",
      "        6.3 Cuestionario Hematología.html               10 Success\n",
      "        6.4 Cuestionario Hematología.html               10 Success\n",
      "        6.5 Cuestionario Hematología.html               10 Success\n",
      "        6.6 Cuestionario Hematología.html               20 Success\n",
      "        6.7 Cuestionario Hematología.html                7 Success\n",
      "       7.1 Cuestionario Infectología.html               20 Success\n",
      "       7.2 Cuestionario Infectología.html               20 Success\n",
      "       7.3 Cuestionario Infectología.html               20 Success\n",
      "       7.4 Cuestionario Infectología.html               20 Success\n",
      "       7.5 Cuestionario Infectología.html               20 Success\n",
      "       7.6 Cuestionario Infectología.html               20 Success\n",
      "       7.7 Cuestionario Infectología.html               11 Success\n",
      "       7.8 Cuestionario Infectología.html                4 Success\n",
      "       8.1 Cuestionario Respiratorio.html               20 Success\n",
      "       8.2 Cuestionario Respiratorio.html               20 Success\n",
      "       8.3 Cuestionario Respiratorio.html               20 Success\n",
      "       8.4 Cuestionario Respiratorio.html               20 Success\n",
      "       8.5 Cuestionario Respiratorio.html               20 Success\n",
      "       8.6 Cuestionario Respiratorio.html               10 Success\n",
      "       8.7 Cuestionario Respiratorio.html                9 Success\n",
      "  9.1 Cuestionario Gastroenterología.html               10 Success\n",
      "  9.2 Cuestionario Gastroenterología.html               20 Success\n",
      "  9.3 Cuestionario Gastroenterología.html               20 Success\n",
      "  9.4 Cuestionario Gastroenterología.html               20 Success\n",
      "  9.5 Cuestionario Gastroenterología.html               20 Success\n",
      " 9.6. Cuestionario Gastroenterología.html               10 Success\n",
      "                     Prueba repaso 1.html                7 Success\n",
      "                     Prueba repaso 2.html                7 Success\n",
      "                     Prueba repaso 3.html                7 Success\n",
      "                     Prueba repaso 4.html               10 Success\n",
      "                     Prueba repaso 5.html                5 Success\n",
      "Reconstrucción Eunacom julio 2024 P1.html               10 Success\n",
      "Reconstrucción Eunacom julio 2024 P2.html               10 Success\n",
      "\n",
      "Average options per question: 5.0\n",
      "\n",
      "Questions per file:\n",
      "  1.1 Cuestionario Diabetes.html: 15 questions\n",
      "  1.2. Cuestionario Diabetes.html: 15 questions\n",
      "  1.3 Cuestionario Diabetes.html: 14 questions\n",
      "  10.2 Cuestionario Neurología.html: 14 questions\n",
      "  10.3 Cuestionario Neurología.html: 20 questions\n",
      "  10.4 Cuestionario Neurología.html: 14 questions\n",
      "  10.5 Cuestionario Neurología.html: 20 questions\n",
      "  10.6 Cuestionario Neurología.html: 7 questions\n",
      "  2.1 Cuestionario Endocrinología.html: 10 questions\n",
      "  2.2 Cuestionario Endocrinología.html: 20 questions\n",
      "  2.3 Cuestionario Endocrinología.html: 13 questions\n",
      "  2.4 Cuestionario Endocrinología.html: 14 questions\n",
      "  2.5 Cuestionario Endocrinología.html: 20 questions\n",
      "  2.6 Cuestionario Endocrinología.html: 10 questions\n",
      "  2.7 Cuestionario Endocrinología.html: 10 questions\n",
      "  2.8 Cuestionario Endocrinología.html: 6 questions\n",
      "  3.1 Cuestionario Cardiología.html: 20 questions\n",
      "  3.2 Cuestionario Cardiología.html: 20 questions\n",
      "  3.3 Cuestionario Cardiología.html: 10 questions\n",
      "  3.4 Cuestionario Cardiología.html: 20 questions\n",
      "  3.5 Cuestionario Cardiología.html: 20 questions\n",
      "  3.6 Cuestionario Cardiología.html: 13 questions\n",
      "  3.7 Cuestionario Cardiología.html: 15 questions\n",
      "  4.1 Cuestionario Nefrología.html: 20 questions\n",
      "  4.2 Cuestionario Nefrología.html: 20 questions\n",
      "  4.3 Cuestionario Nefrología.html: 20 questions\n",
      "  4.4 Cuestionario Nefrología.html: 20 questions\n",
      "  4.5 Cuestionario Nefrología.html: 10 questions\n",
      "  4.6 Cuestionario Nefrología.html: 10 questions\n",
      "  4.7 Cuestionario Nefrología.html: 10 questions\n",
      "  4.8 Cuestionario Nefrología.html: 7 questions\n",
      "  5.1 Cuestionario Reumatología.html: 20 questions\n",
      "  5.2 Cuestionario Reumatología.html: 20 questions\n",
      "  5.3 Cuestionario Reumatología.html: 10 questions\n",
      "  5.4 Cuestionario Reumatología.html: 7 questions\n",
      "  6.1 Cuestionario Hematología.html: 20 questions\n",
      "  6.2 Cuestionario Hematología.html: 20 questions\n",
      "  6.3 Cuestionario Hematología.html: 10 questions\n",
      "  6.4 Cuestionario Hematología.html: 10 questions\n",
      "  6.5 Cuestionario Hematología.html: 10 questions\n",
      "  6.6 Cuestionario Hematología.html: 20 questions\n",
      "  6.7 Cuestionario Hematología.html: 7 questions\n",
      "  7.1 Cuestionario Infectología.html: 20 questions\n",
      "  7.2 Cuestionario Infectología.html: 20 questions\n",
      "  7.3 Cuestionario Infectología.html: 20 questions\n",
      "  7.4 Cuestionario Infectología.html: 20 questions\n",
      "  7.5 Cuestionario Infectología.html: 20 questions\n",
      "  7.6 Cuestionario Infectología.html: 20 questions\n",
      "  7.7 Cuestionario Infectología.html: 11 questions\n",
      "  7.8 Cuestionario Infectología.html: 4 questions\n",
      "  8.1 Cuestionario Respiratorio.html: 20 questions\n",
      "  8.2 Cuestionario Respiratorio.html: 20 questions\n",
      "  8.3 Cuestionario Respiratorio.html: 20 questions\n",
      "  8.4 Cuestionario Respiratorio.html: 20 questions\n",
      "  8.5 Cuestionario Respiratorio.html: 20 questions\n",
      "  8.6 Cuestionario Respiratorio.html: 10 questions\n",
      "  8.7 Cuestionario Respiratorio.html: 9 questions\n",
      "  9.1 Cuestionario Gastroenterología.html: 10 questions\n",
      "  9.2 Cuestionario Gastroenterología.html: 20 questions\n",
      "  9.3 Cuestionario Gastroenterología.html: 20 questions\n",
      "  9.4 Cuestionario Gastroenterología.html: 20 questions\n",
      "  9.5 Cuestionario Gastroenterología.html: 20 questions\n",
      "  9.6. Cuestionario Gastroenterología.html: 10 questions\n",
      "  Prueba repaso 1.html: 7 questions\n",
      "  Prueba repaso 2.html: 7 questions\n",
      "  Prueba repaso 3.html: 7 questions\n",
      "  Prueba repaso 4.html: 10 questions\n",
      "  Prueba repaso 5.html: 5 questions\n",
      "  Reconstrucción Eunacom julio 2024 P1.html: 10 questions\n",
      "  Reconstrucción Eunacom julio 2024 P2.html: 10 questions\n",
      "\n",
      "================================================================================\n",
      "PROCESSING COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:49:17.017354Z",
     "start_time": "2025-10-19T21:49:16.954166Z"
    }
   },
   "cell_type": "code",
   "source": "all_questions",
   "id": "bc1d6ea822e55b79",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mall_questions\u001B[49m\n",
      "\u001B[31mNameError\u001B[39m: name 'all_questions' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:48:52.080691Z",
     "start_time": "2025-10-19T21:48:51.978238Z"
    }
   },
   "cell_type": "code",
   "source": "df.head().to_dicts()",
   "id": "7974e3bd83ea606a",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_dicts'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_28648\\2369893936.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m df.head().to_dicts()\n",
      "\u001B[32m~\\DataspellProjects\\kverse\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   6314\u001B[39m             \u001B[38;5;28;01mand\u001B[39;00m name \u001B[38;5;28;01mnot\u001B[39;00m \u001B[38;5;28;01min\u001B[39;00m self._accessors\n\u001B[32m   6315\u001B[39m             \u001B[38;5;28;01mand\u001B[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001B[32m   6316\u001B[39m         ):\n\u001B[32m   6317\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m self[name]\n\u001B[32m-> \u001B[39m\u001B[32m6318\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m object.__getattribute__(self, name)\n",
      "\u001B[31mAttributeError\u001B[39m: 'DataFrame' object has no attribute 'to_dicts'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "373cb870d45ed167"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e1c6530c30eb4d0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T19:41:56.052692Z",
     "start_time": "2025-10-19T19:41:56.050074Z"
    }
   },
   "cell_type": "code",
   "source": "path = r\"C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\\view-source_https___cursosonline.doctorguevara.cl_mod_quiz_review.php_attempt=1263771&cmid=125317.html\"",
   "id": "c3975e8fc2e75ad0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "39e0763d32d6d4ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9966ba5d927bdcf1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T19:52:04.281630Z",
     "start_time": "2025-10-19T19:52:03.507379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "path = r\"C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\\view-source_https___cursosonline.doctorguevara.cl_mod_quiz_review.php_attempt=1263771&cmid=125317.html\"\n",
    "\n",
    "print(\"Reading view-source HTML file...\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    view_source_html = f.read()\n",
    "\n",
    "print(f\"File size: {len(view_source_html)} characters\\n\")\n",
    "\n",
    "# Parse the view-source page\n",
    "print(\"Extracting actual HTML from view-source format...\")\n",
    "soup_viewsource = BeautifulSoup(view_source_html, \"html.parser\")\n",
    "\n",
    "# Find all line-content cells\n",
    "line_contents = soup_viewsource.find_all(\"td\", class_=\"line-content\")\n",
    "print(f\"Found {len(line_contents)} lines of code\\n\")\n",
    "\n",
    "if not line_contents:\n",
    "    print(\"✗ Could not find line-content elements. This might not be a view-source file.\")\n",
    "    exit()\n",
    "\n",
    "# Extract and reconstruct the actual HTML\n",
    "actual_html_lines = []\n",
    "for line_td in line_contents:\n",
    "    # Get all text from this line, which will include the HTML\n",
    "    line_text = line_td.get_text()\n",
    "    actual_html_lines.append(line_text)\n",
    "\n",
    "# Join all lines to get the complete HTML\n",
    "actual_html = \"\\n\".join(actual_html_lines)\n",
    "\n",
    "print(f\"Reconstructed HTML size: {len(actual_html)} characters\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Now parse the ACTUAL HTML\n",
    "soup = BeautifulSoup(actual_html, \"html.parser\")\n",
    "\n",
    "print(\"SEARCHING FOR QUESTIONS IN RECONSTRUCTED HTML\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Search for questions\n",
    "questions = soup.find_all(\"div\", id=re.compile(r\"question-\\d+-\\d+\"))\n",
    "print(f\"Questions found: {len(questions)}\\n\")\n",
    "\n",
    "if not questions:\n",
    "    print(\"Still no questions found. Trying alternative patterns...\")\n",
    "    questions = soup.find_all(\"div\", class_=re.compile(r\"que.*multichoice\"))\n",
    "    print(f\"Questions with 'que multichoice' class: {len(questions)}\\n\")\n",
    "\n",
    "if not questions:\n",
    "    print(\"✗ No questions found even after reconstruction\")\n",
    "    print(\"\\nShowing sample of reconstructed HTML (chars 50000-50500):\")\n",
    "    print(actual_html[50000:50500])\n",
    "    exit()\n",
    "\n",
    "print(f\"✓ Successfully found {len(questions)} questions!\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXTRACTING QUESTION DATA\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Extract data\n",
    "data = []\n",
    "\n",
    "for question in questions:\n",
    "    try:\n",
    "        # Question number\n",
    "        qno_span = question.find(\"span\", class_=\"qno\")\n",
    "        q_number = qno_span.get_text(strip=True) if qno_span else \"?\"\n",
    "\n",
    "        # State\n",
    "        state_div = question.find(\"div\", class_=\"state\")\n",
    "        q_state = state_div.get_text(strip=True) if state_div else \"N/A\"\n",
    "\n",
    "        # Question text\n",
    "        qtext_div = question.find(\"div\", class_=\"qtext\")\n",
    "        if qtext_div:\n",
    "            # Remove tables to get clean question text\n",
    "            for table in qtext_div.find_all(\"table\"):\n",
    "                table.decompose()\n",
    "            q_text = qtext_div.get_text(strip=True, separator=\" \")\n",
    "        else:\n",
    "            q_text = \"N/A\"\n",
    "\n",
    "        # Find answer options\n",
    "        answer_divs = question.find_all(\"div\", class_=re.compile(r\"^r[0-1]$\"))\n",
    "\n",
    "        correct_answer = None\n",
    "        user_answer = None\n",
    "        all_answers = []\n",
    "\n",
    "        for ans_div in answer_divs:\n",
    "            # Find the label with answer text\n",
    "            label = ans_div.find(\"div\", class_=\"d-flex\")\n",
    "            if label:\n",
    "                letter_span = label.find(\"span\", class_=\"answernumber\")\n",
    "                text_div = label.find(\"div\", class_=\"flex-fill\")\n",
    "\n",
    "                if letter_span and text_div:\n",
    "                    letter = letter_span.get_text(strip=True)\n",
    "                    text = text_div.get_text(strip=True)\n",
    "                    answer_full = f\"{letter} {text}\"\n",
    "\n",
    "                    all_answers.append(answer_full)\n",
    "\n",
    "                    # Check if this is correct\n",
    "                    if \"correct\" in ans_div.get(\"class\", []):\n",
    "                        correct_answer = answer_full\n",
    "\n",
    "                    # Check if this was selected by user\n",
    "                    radio_input = ans_div.find(\"input\", type=\"radio\")\n",
    "                    if radio_input and radio_input.get(\"checked\"):\n",
    "                        user_answer = answer_full\n",
    "\n",
    "        # Get feedback/explanation\n",
    "        feedback_div = question.find(\"div\", class_=\"generalfeedback\")\n",
    "        feedback = feedback_div.get_text(strip=True, separator=\" \") if feedback_div else \"\"\n",
    "\n",
    "        # Determine if answer was correct\n",
    "        was_correct = q_state == \"Correcta\"\n",
    "\n",
    "        data.append(\n",
    "            {\n",
    "                \"Q#\": q_number,\n",
    "                \"Status\": \"✓\" if was_correct else \"✗\",\n",
    "                \"Question\": q_text[:200] + \"...\" if len(q_text) > 200 else q_text,\n",
    "                \"Your_Answer\": user_answer if user_answer else correct_answer,\n",
    "                \"Correct_Answer\": correct_answer or \"N/A\",\n",
    "                \"Explanation\": feedback[:350] + \"...\" if len(feedback) > 350 else feedback,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        status_icon = \"✓\" if was_correct else \"✗\"\n",
    "        print(f\"{status_icon} Q{q_number}: {q_state} - {correct_answer[:60] if correct_answer else 'N/A'}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing question: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Create DataFrame\n",
    "if data:\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXTRACTION COMPLETE - SUMMARY TABLE\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    # Display summary\n",
    "    summary_df = df[[\"Q#\", \"Status\", \"Correct_Answer\"]].copy()\n",
    "    summary_df[\"Correct_Answer\"] = summary_df[\"Correct_Answer\"].str[:80]\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    # Save files\n",
    "    output_excel = \"quiz_results.xlsx\"\n",
    "    output_csv = \"quiz_results.csv\"\n",
    "\n",
    "    df.to_excel(output_excel, index=False, engine=\"openpyxl\")\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"\\n✓ Saved to: {output_excel}\")\n",
    "    print(f\"✓ Saved to: {output_csv}\")\n",
    "\n",
    "    # Statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"QUIZ STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    total = len(df)\n",
    "    correct = len(df[df[\"Status\"] == \"✓\"])\n",
    "    incorrect = total - correct\n",
    "    percentage = (correct / total * 100) if total > 0 else 0\n",
    "\n",
    "    print(f\"Total Questions: {total}\")\n",
    "    print(f\"Correct: {correct}\")\n",
    "    print(f\"Incorrect: {incorrect}\")\n",
    "    print(f\"Score: {percentage:.2f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n✗ No data was extracted\")"
   ],
   "id": "dd6ae1f16a6d6d60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading view-source HTML file...\n",
      "File size: 1074933 characters\n",
      "\n",
      "Extracting actual HTML from view-source format...\n",
      "Found 2815 lines of code\n",
      "\n",
      "Reconstructed HTML size: 244337 characters\n",
      "================================================================================\n",
      "SEARCHING FOR QUESTIONS IN RECONSTRUCTED HTML\n",
      "================================================================================\n",
      "Questions found: 15\n",
      "\n",
      "✓ Successfully found 15 questions!\n",
      "\n",
      "================================================================================\n",
      "EXTRACTING QUESTION DATA\n",
      "================================================================================\n",
      "\n",
      "✓ Q1: Correcta - c. Aumentar la insulina cristalina del almuerzo y cena...\n",
      "✓ Q2: Correcta - d. Iniciar un fibrato...\n",
      "✓ Q3: Correcta - a. Test de tolerancia a la glucosa...\n",
      "✓ Q4: Correcta - e. Niveles plasmáticos de péptido C...\n",
      "✓ Q5: Correcta - d. iECAs...\n",
      "✓ Q6: Correcta - c. Iniciar insulina...\n",
      "✓ Q7: Correcta - e. Hospitalizar, iniciar insulinoterapia y venlafaxina oral...\n",
      "✓ Q8: Correcta - e. Iniciar insulina...\n",
      "✓ Q9: Correcta - c. Indicar dieta e iniciar una estatina...\n",
      "✓ Q10: Correcta - c. Hipoglicemia facticia por glibenclamida...\n",
      "✓ Q11: Correcta - c. Iniciar insulina es esquema intensificado, con una dosis ...\n",
      "✓ Q12: Correcta - c. Iniciar dieta y un fibrato...\n",
      "✓ Q13: Correcta - a. Agregar glibenclamida y mantener la metformina...\n",
      "✗ Q14: Incorrecta - N/A...\n",
      "✓ Q15: Correcta - e. Iniciar insulina y valsartán...\n",
      "\n",
      "================================================================================\n",
      "EXTRACTION COMPLETE - SUMMARY TABLE\n",
      "================================================================================\n",
      "\n",
      "Q# Status                                                                   Correct_Answer\n",
      " 1      ✓                           c. Aumentar la insulina cristalina del almuerzo y cena\n",
      " 2      ✓                                                            d. Iniciar un fibrato\n",
      " 3      ✓                                               a. Test de tolerancia a la glucosa\n",
      " 4      ✓                                              e. Niveles plasmáticos de péptido C\n",
      " 5      ✓                                                                         d. iECAs\n",
      " 6      ✓                                                              c. Iniciar insulina\n",
      " 7      ✓                      e. Hospitalizar, iniciar insulinoterapia y venlafaxina oral\n",
      " 8      ✓                                                              e. Iniciar insulina\n",
      " 9      ✓                                          c. Indicar dieta e iniciar una estatina\n",
      "10      ✓                                       c. Hipoglicemia facticia por glibenclamida\n",
      "11      ✓ c. Iniciar insulina es esquema intensificado, con una dosis de insulina ultralen\n",
      "12      ✓                                                    c. Iniciar dieta y un fibrato\n",
      "13      ✓                                a. Agregar glibenclamida y mantener la metformina\n",
      "14      ✗                                                                              N/A\n",
      "15      ✓                                                  e. Iniciar insulina y valsartán\n",
      "\n",
      "✓ Saved to: quiz_results.xlsx\n",
      "✓ Saved to: quiz_results.csv\n",
      "\n",
      "================================================================================\n",
      "QUIZ STATISTICS\n",
      "================================================================================\n",
      "Total Questions: 15\n",
      "Correct: 14\n",
      "Incorrect: 1\n",
      "Score: 93.33%\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T19:57:23.821313Z",
     "start_time": "2025-10-19T19:57:23.325960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "path = r\"C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\\view-source_https___cursosonline.doctorguevara.cl_mod_quiz_review.php_attempt=1263771&cmid=125317.html\"\n",
    "\n",
    "print(\"Reading view-source HTML file...\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    view_source_html = f.read()\n",
    "\n",
    "print(f\"File size: {len(view_source_html)} characters\\n\")\n",
    "\n",
    "# Parse the view-source page\n",
    "print(\"Extracting actual HTML from view-source format...\")\n",
    "soup_viewsource = BeautifulSoup(view_source_html, \"html.parser\")\n",
    "\n",
    "# Find all line-content cells\n",
    "line_contents = soup_viewsource.find_all(\"td\", class_=\"line-content\")\n",
    "print(f\"Found {len(line_contents)} lines of code\\n\")\n",
    "\n",
    "if not line_contents:\n",
    "    print(\"✗ Could not find line-content elements.\")\n",
    "    exit()\n",
    "\n",
    "# Reconstruct the actual HTML\n",
    "actual_html_lines = []\n",
    "for line_td in line_contents:\n",
    "    line_text = line_td.get_text()\n",
    "    actual_html_lines.append(line_text)\n",
    "\n",
    "actual_html = \"\\n\".join(actual_html_lines)\n",
    "print(f\"Reconstructed HTML size: {len(actual_html)} characters\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Parse the ACTUAL HTML\n",
    "soup = BeautifulSoup(actual_html, \"html.parser\")\n",
    "\n",
    "print(\"SEARCHING FOR QUESTIONS IN RECONSTRUCTED HTML\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Search for questions\n",
    "questions = soup.find_all(\"div\", id=re.compile(r\"question-\\d+-\\d+\"))\n",
    "print(f\"Questions found: {len(questions)}\\n\")\n",
    "\n",
    "if not questions:\n",
    "    print(\"✗ No questions found\")\n",
    "    exit()\n",
    "\n",
    "print(f\"✓ Successfully found {len(questions)} questions!\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXTRACTING QUESTION DATA (FULL TEXT, NO TRUNCATION)\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Extract data\n",
    "quiz_data = []\n",
    "\n",
    "for idx, question in enumerate(questions, 1):\n",
    "    try:\n",
    "        # Extract question ID from the div id attribute\n",
    "        question_id = question.get(\"id\", \"\")\n",
    "\n",
    "        # Question number\n",
    "        qno_span = question.find(\"span\", class_=\"qno\")\n",
    "        q_number = qno_span.get_text(strip=True) if qno_span else str(idx)\n",
    "\n",
    "        # Question text - FULL TEXT, NO TRUNCATION\n",
    "        qtext_div = question.find(\"div\", class_=\"qtext\")\n",
    "        if qtext_div:\n",
    "            # Remove tables but keep the rest\n",
    "            qtext_copy = qtext_div.__copy__()\n",
    "            for table in qtext_copy.find_all(\"table\"):\n",
    "                table.decompose()\n",
    "            q_text = qtext_copy.get_text(strip=True, separator=\" \")\n",
    "        else:\n",
    "            q_text = \"\"\n",
    "\n",
    "        # Find ALL answer options\n",
    "        answer_divs = question.find_all(\"div\", class_=re.compile(r\"^r[0-1]$\"))\n",
    "\n",
    "        correct_answer = None\n",
    "        correct_explanation = None\n",
    "        all_options = []\n",
    "\n",
    "        for ans_div in answer_divs:\n",
    "            # Find the label with answer text\n",
    "            label = ans_div.find(\"div\", class_=\"d-flex\")\n",
    "            if label:\n",
    "                letter_span = label.find(\"span\", class_=\"answernumber\")\n",
    "                text_div = label.find(\"div\", class_=\"flex-fill\")\n",
    "\n",
    "                if letter_span and text_div:\n",
    "                    letter = letter_span.get_text(strip=True)\n",
    "                    text = text_div.get_text(strip=True)\n",
    "\n",
    "                    # Check if this is correct\n",
    "                    is_correct = \"correct\" in ans_div.get(\"class\", [])\n",
    "\n",
    "                    option_dict = {\"letter\": letter, \"text\": text, \"is_correct\": is_correct}\n",
    "\n",
    "                    all_options.append(option_dict)\n",
    "\n",
    "                    if is_correct:\n",
    "                        correct_answer = f\"{letter} {text}\"\n",
    "\n",
    "        # Get feedback/explanation - FULL TEXT\n",
    "        feedback_div = question.find(\"div\", class_=\"generalfeedback\")\n",
    "        feedback = feedback_div.get_text(strip=True, separator=\" \") if feedback_div else \"\"\n",
    "\n",
    "        # Get the \"correct answer\" text at the end\n",
    "        rightanswer_div = question.find(\"div\", class_=\"rightanswer\")\n",
    "        right_answer_text = rightanswer_div.get_text(strip=True) if rightanswer_div else \"\"\n",
    "\n",
    "        # Try to extract topic from question text or feedback (first sentence or similar)\n",
    "        # This is a simple heuristic - you may want to adjust\n",
    "        topic = q_text.split(\".\")[0][:100] if q_text else \"Tema no especificado\"\n",
    "\n",
    "        # Structure the data as requested\n",
    "        question_data = {\n",
    "            \"question_id\": question_id.split(\"-\")[-1] if question_id else str(idx),\n",
    "            \"question_number\": q_number,\n",
    "            \"topic\": topic,\n",
    "            \"question_text\": q_text,\n",
    "            \"answer_options\": all_options,  # List of all options\n",
    "            \"correct_answer\": correct_answer,\n",
    "            \"explanation\": feedback,\n",
    "            \"right_answer_text\": right_answer_text,\n",
    "            \"source_exam\": \"GUEVARA - Diabetes Quiz\",  # You can modify this\n",
    "        }\n",
    "\n",
    "        quiz_data.append(question_data)\n",
    "\n",
    "        print(\n",
    "            f\"✓ Q{q_number} extracted: {len(all_options)} options, {len(q_text)} chars question, {len(feedback)} chars explanation\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing question {idx}: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Save as JSON\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_json = \"quiz_data_complete.json\"\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(quiz_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✓ Saved complete data to: {output_json}\")\n",
    "\n",
    "# Also create a flattened version for Excel/CSV\n",
    "flattened_data = []\n",
    "for q in quiz_data:\n",
    "    # Create a row with all answer options as separate columns\n",
    "    row = {\n",
    "        \"question_id\": q[\"question_id\"],\n",
    "        \"question_number\": q[\"question_number\"],\n",
    "        \"topic\": q[\"topic\"],\n",
    "        \"question_text\": q[\"question_text\"],\n",
    "        \"correct_answer\": q[\"correct_answer\"],\n",
    "        \"explanation\": q[\"explanation\"],\n",
    "        \"source_exam\": q[\"source_exam\"],\n",
    "    }\n",
    "\n",
    "    # Add each answer option as a column\n",
    "    for i, opt in enumerate(q[\"answer_options\"], 1):\n",
    "        row[f\"option_{i}\"] = f\"{opt['letter']} {opt['text']}\"\n",
    "        row[f\"option_{i}_correct\"] = \"SÍ\" if opt[\"is_correct\"] else \"NO\"\n",
    "\n",
    "    flattened_data.append(row)\n",
    "\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "output_excel = \"quiz_data_complete.xlsx\"\n",
    "output_csv = \"quiz_data_complete.csv\"\n",
    "\n",
    "df.to_excel(output_excel, index=False, engine=\"openpyxl\")\n",
    "df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✓ Saved flattened data to: {output_excel}\")\n",
    "print(f\"✓ Saved flattened data to: {output_csv}\")\n",
    "\n",
    "# Print sample\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE OUTPUT (First Question)\")\n",
    "print(\"=\" * 80)\n",
    "if quiz_data:\n",
    "    print(json.dumps(quiz_data[0], ensure_ascii=False, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total questions extracted: {len(quiz_data)}\")\n",
    "if quiz_data:\n",
    "    avg_options = sum(len(q[\"answer_options\"]) for q in quiz_data) / len(quiz_data)\n",
    "    avg_question_length = sum(len(q[\"question_text\"]) for q in quiz_data) / len(quiz_data)\n",
    "    avg_explanation_length = sum(len(q[\"explanation\"]) for q in quiz_data) / len(quiz_data)\n",
    "\n",
    "    print(f\"Average options per question: {avg_options:.1f}\")\n",
    "    print(f\"Average question length: {avg_question_length:.0f} characters\")\n",
    "    print(f\"Average explanation length: {avg_explanation_length:.0f} characters\")"
   ],
   "id": "46974ae9eb43b094",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading view-source HTML file...\n",
      "File size: 1074933 characters\n",
      "\n",
      "Extracting actual HTML from view-source format...\n",
      "Found 2815 lines of code\n",
      "\n",
      "Reconstructed HTML size: 244337 characters\n",
      "================================================================================\n",
      "SEARCHING FOR QUESTIONS IN RECONSTRUCTED HTML\n",
      "================================================================================\n",
      "Questions found: 15\n",
      "\n",
      "✓ Successfully found 15 questions!\n",
      "\n",
      "================================================================================\n",
      "EXTRACTING QUESTION DATA (FULL TEXT, NO TRUNCATION)\n",
      "================================================================================\n",
      "\n",
      "✓ Q1 extracted: 5 options, 311 chars question, 829 chars explanation\n",
      "✓ Q2 extracted: 5 options, 193 chars question, 446 chars explanation\n",
      "✓ Q3 extracted: 5 options, 207 chars question, 283 chars explanation\n",
      "✓ Q4 extracted: 5 options, 411 chars question, 776 chars explanation\n",
      "✓ Q5 extracted: 5 options, 125 chars question, 662 chars explanation\n",
      "✓ Q6 extracted: 5 options, 232 chars question, 675 chars explanation\n",
      "✓ Q7 extracted: 5 options, 408 chars question, 610 chars explanation\n",
      "✓ Q8 extracted: 5 options, 321 chars question, 505 chars explanation\n",
      "✓ Q9 extracted: 5 options, 433 chars question, 450 chars explanation\n",
      "✓ Q10 extracted: 5 options, 365 chars question, 663 chars explanation\n",
      "✓ Q11 extracted: 5 options, 237 chars question, 719 chars explanation\n",
      "✓ Q12 extracted: 5 options, 209 chars question, 491 chars explanation\n",
      "✓ Q13 extracted: 5 options, 238 chars question, 1031 chars explanation\n",
      "✓ Q14 extracted: 5 options, 317 chars question, 719 chars explanation\n",
      "✓ Q15 extracted: 5 options, 274 chars question, 549 chars explanation\n",
      "\n",
      "================================================================================\n",
      "SAVING DATA\n",
      "================================================================================\n",
      "✓ Saved complete data to: quiz_data_complete.json\n",
      "✓ Saved flattened data to: quiz_data_complete.xlsx\n",
      "✓ Saved flattened data to: quiz_data_complete.csv\n",
      "\n",
      "================================================================================\n",
      "SAMPLE OUTPUT (First Question)\n",
      "================================================================================\n",
      "{\n",
      "  \"question_id\": \"1\",\n",
      "  \"question_number\": \"1\",\n",
      "  \"topic\": \"Un paciente de 20 años, diabético tipo 1, en tratamiento con una dosis de Lantus (insulina glargina)\",\n",
      "  \"question_text\": \"Un paciente de 20 años, diabético tipo 1, en tratamiento con una dosis de Lantus (insulina glargina) en la noche y tres dosis de insulina cristalina, previas al desayuno, almuerzo y cena, presenta la siguiente tabla de glicemias promedio: Además su hemoglobina glicosilada es de 8%. La conducta más adecuada es:\",\n",
      "  \"answer_options\": [\n",
      "    {\n",
      "      \"letter\": \"a.\",\n",
      "      \"text\": \"Aumentar la dosis de Lantus\",\n",
      "      \"is_correct\": false\n",
      "    },\n",
      "    {\n",
      "      \"letter\": \"b.\",\n",
      "      \"text\": \"Aumentar la insulina cristalina del desayuno y del almuerzo\",\n",
      "      \"is_correct\": false\n",
      "    },\n",
      "    {\n",
      "      \"letter\": \"c.\",\n",
      "      \"text\": \"Aumentar la insulina cristalina del almuerzo y cena\",\n",
      "      \"is_correct\": true\n",
      "    },\n",
      "    {\n",
      "      \"letter\": \"d.\",\n",
      "      \"text\": \"Aumentar la dosis de Lantus y de las 3 insulinas cristalinas\",\n",
      "      \"is_correct\": false\n",
      "    },\n",
      "    {\n",
      "      \"letter\": \"e.\",\n",
      "      \"text\": \"Agregar una dosis matinal de Lantus\",\n",
      "      \"is_correct\": false\n",
      "    }\n",
      "  ],\n",
      "  \"correct_answer\": \"c. Aumentar la insulina cristalina del almuerzo y cena\",\n",
      "  \"explanation\": \"La glicemias preprandial dependen de la insulina lenta (NPH, glargina u otra ultralenta) recibida hace varias horas atrás (ej. la de ayuno depende de la NPH nocturna). En cambio, las glicemias postprandiales dependen de la insulina rápida (ultrarrápida o cristalina), aunque también dependen de la glicemia preprandial y de la comida misma. En este caso, las glicemias postalmuerzo y postcena son las que están elevadas, por lo que se debe aumentar la insulina cristalina de esos horarios. Recordar que el objetivo de glicemias es preprandiales menores a 130 mg/dl (idealmente menor a 100) y postprandiales menores a 180 mg/dl (idealmente menor a 130), pero que lo más importante es la hemoglobina glicosilada menor a 7%. La insulina lantus (glargina) se tendría que elevar si es que las glicemias precomidas estuvieran elevadas.\",\n",
      "  \"right_answer_text\": \"La respuesta correcta es: Aumentar la insulina cristalina del almuerzo y cena\",\n",
      "  \"source_exam\": \"GUEVARA - Diabetes Quiz\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "STATISTICS\n",
      "================================================================================\n",
      "Total questions extracted: 15\n",
      "Average options per question: 5.0\n",
      "Average question length: 285 characters\n",
      "Average explanation length: 627 characters\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T19:57:29.722510Z",
     "start_time": "2025-10-19T19:57:29.715774Z"
    }
   },
   "cell_type": "code",
   "source": "quiz_data",
   "id": "1917c172f112426d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question_id': '1',\n",
       "  'question_number': '1',\n",
       "  'topic': 'Un paciente de 20 años, diabético tipo 1, en tratamiento con una dosis de Lantus (insulina glargina)',\n",
       "  'question_text': 'Un paciente de 20 años, diabético tipo 1, en tratamiento con una dosis de Lantus (insulina glargina) en la noche y tres dosis de insulina cristalina, previas al desayuno, almuerzo y cena, presenta la siguiente tabla de glicemias promedio: Además su hemoglobina glicosilada es de 8%. La conducta más adecuada es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Aumentar la dosis de Lantus',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Aumentar la insulina cristalina del desayuno y del almuerzo',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Aumentar la insulina cristalina del almuerzo y cena',\n",
       "    'is_correct': True},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Aumentar la dosis de Lantus y de las 3 insulinas cristalinas',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.',\n",
       "    'text': 'Agregar una dosis matinal de Lantus',\n",
       "    'is_correct': False}],\n",
       "  'correct_answer': 'c. Aumentar la insulina cristalina del almuerzo y cena',\n",
       "  'explanation': 'La glicemias preprandial dependen de la insulina lenta (NPH, glargina u otra ultralenta) recibida hace varias horas atrás (ej. la de ayuno depende de la NPH nocturna). En cambio, las glicemias postprandiales dependen de la insulina rápida (ultrarrápida o cristalina), aunque también dependen de la glicemia preprandial y de la comida misma. En este caso, las glicemias postalmuerzo y postcena son las que están elevadas, por lo que se debe aumentar la insulina cristalina de esos horarios. Recordar que el objetivo de glicemias es preprandiales menores a 130 mg/dl (idealmente menor a 100) y postprandiales menores a 180 mg/dl (idealmente menor a 130), pero que lo más importante es la hemoglobina glicosilada menor a 7%. La insulina lantus (glargina) se tendría que elevar si es que las glicemias precomidas estuvieran elevadas.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Aumentar la insulina cristalina del almuerzo y cena',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '2',\n",
       "  'question_number': '2',\n",
       "  'topic': 'Un paciente diabético de 50 años, en tratamiento con dieta, se realiza una prueba de lípidos, que mu',\n",
       "  'question_text': 'Un paciente diabético de 50 años, en tratamiento con dieta, se realiza una prueba de lípidos, que muestra Colesterol LDL de 120 mg/dl, TG: 600 mg/dl, HDL: 30 mg/dl. La conducta más adecuada es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Manejar con dieta',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.', 'text': 'Iniciar insulina', 'is_correct': False},\n",
       "   {'letter': 'c.', 'text': 'Iniciar una estatina', 'is_correct': False},\n",
       "   {'letter': 'd.', 'text': 'Iniciar un fibrato', 'is_correct': True},\n",
       "   {'letter': 'e.', 'text': 'Iniciar ácido nicotínico', 'is_correct': False}],\n",
       "  'correct_answer': 'd. Iniciar un fibrato',\n",
       "  'explanation': 'Por ser diabético, la meta de LDL es menor a 70, por lo que está elevada. Además tiene TG elevados (> 150) y HDL bajo (<40), por lo que el diagnóstico es una dislipidemia mixta. Si bien la regla general es que el LDL es la prioridad, en este caso tiene TG mayores a 500, por lo que la hipertrigliceridemia pasa a ser la prioridad y se debe tratar con fibrato. Si los TG hubiesen sido menores a 500 (ej. 400), la respuesta habría sido la estatina.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Iniciar un fibrato',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '3',\n",
       "  'question_number': '3',\n",
       "  'topic': 'Un paciente de 60 años se realiza una glicemia de ayuno, que resulta 120 mg/dl',\n",
       "  'question_text': 'Un paciente de 60 años se realiza una glicemia de ayuno, que resulta 120 mg/dl. No ha presentado síntomas y su examen físico es normal. ¿Qué examen es más adecuado para proseguir el estudio de este paciente?',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Test de tolerancia a la glucosa',\n",
       "    'is_correct': True},\n",
       "   {'letter': 'b.', 'text': 'Glicemia de ayuno', 'is_correct': False},\n",
       "   {'letter': 'c.', 'text': 'Índice de HOMA', 'is_correct': False},\n",
       "   {'letter': 'd.', 'text': 'Hemoglobina glicosilada', 'is_correct': False},\n",
       "   {'letter': 'e.', 'text': 'Insulinemia basal', 'is_correct': False}],\n",
       "  'correct_answer': 'a. Test de tolerancia a la glucosa',\n",
       "  'explanation': 'Recordar que si la glicemia es menor a 100 se considera normal y se da de alta; si está entre 100 y 125 se pide un TTGO y si está mayor a 125, se repite, para confirmar el diagnóstico de diabetes mellitus. En el embarazo, en cambio, las glicemias mayores o iguales a 100, se repiten.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Test de tolerancia a la glucosa',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '4',\n",
       "  'question_number': '4',\n",
       "  'topic': 'Una paciente de 65 años, sin antecedentes mórbidos conocidos presenta un cuadro de palpitaciones, ma',\n",
       "  'question_text': 'Una paciente de 65 años, sin antecedentes mórbidos conocidos presenta un cuadro de palpitaciones, malestar y sudoración, luego de estar 5 horas sin comer. El cuadro se repite varias veces, siempre en relación al ayuno, por lo que decide hacerse un hemoglucotest, que demuestra una glicemia de 45 mg/dl durante uno de los episodios. ¿Qué examen es el más adecuado para determinar la etiología de la hipoglicemia?',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Glicemia de ayuno',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Test de tolerancia a la glucosa',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Niveles plasmáticos de insulina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Niveles plasmáticos de glucagón',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.',\n",
       "    'text': 'Niveles plasmáticos de péptido C',\n",
       "    'is_correct': True}],\n",
       "  'correct_answer': 'e. Niveles plasmáticos de péptido C',\n",
       "  'explanation': 'Tiene hipoglicemias de ayuno (recordar que las causas son los insulinomas, el cáncer, enfermedades autoinmunes, la IRC y el DHC). Se estudian con péptido C, que refleja la producción de insulina endógena y que es más estable que la insulina, por lo que su medición es más precisa (aunque también se suele pedir la insulina, junto con el péptido C). Si está alto el péptido C, es un insulinoma u otra causa hiperproductora de insulina; si está bajo se buscan las otras causas; si el péptido C está bajo, pero la insulina está alta, se asume que hay una hipoglicemia facticia por inyecciones de insulina exógena. En cambio las hipoglicemias reactivas (2 a 4 horas postprandiales) se estudian con la prueba de tolerancia a la comida mixta, que desplazó al TTGO de larga duración.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Niveles plasmáticos de péptido C',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '5',\n",
       "  'question_number': '5',\n",
       "  'topic': '¿Qué tratamiento está indicado ante la aparición de microalbuminuria persistente en un paciente con ',\n",
       "  'question_text': '¿Qué tratamiento está indicado ante la aparición de microalbuminuria persistente en un paciente con diabetes mellitus tipo 2?',\n",
       "  'answer_options': [{'letter': 'a.', 'text': 'Insulina', 'is_correct': False},\n",
       "   {'letter': 'b.', 'text': 'Dieta hipoproteica', 'is_correct': False},\n",
       "   {'letter': 'c.', 'text': 'Dieta hiperproteica', 'is_correct': False},\n",
       "   {'letter': 'd.', 'text': 'iECAs', 'is_correct': True},\n",
       "   {'letter': 'e.', 'text': 'Atorvastatina', 'is_correct': False}],\n",
       "  'correct_answer': 'd. iECAs',\n",
       "  'explanation': 'La microalbuminuria (mayor a 30 mg/día o RAC mayor a 0,03) persistente (mayor a 3 meses) es diagnóstica de nefropatía diabética inicial, que se maneja con IECA (enalapril, lisinopril; el captopril se usa menos, por tener que tomarse 3 veces al día). La insulina sí está indicada en la nefropatía diabética, pero en la nefropatía establecida, con caída del clearence de creatinina y creatininemia mayor a 1,4 (en estos casos también son aceptables los GLP-1, como el liraglutide y la semaglutida; los SGLT-2 como la empaglifozina sirven, pero no en IRC con clearence menor a 30 ml/min). En lugar de los IECA, también sirven los ARA2, como el losartán o valsartán.',\n",
       "  'right_answer_text': 'La respuesta correcta es: iECAs',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '6',\n",
       "  'question_number': '6',\n",
       "  'topic': 'Un paciente de 55 años, diabético tipo 2 en tratamiento con metformina 500 mg c/12 horas, presenta h',\n",
       "  'question_text': 'Un paciente de 55 años, diabético tipo 2 en tratamiento con metformina 500 mg c/12 horas, presenta hemoglobina glicosilada de 8,5%, creatinina plasmática de 1,8 mg/dl y proteinuria de 24 horas de 500 mg. La conducta más adecuada es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Agregar glibenclamida',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Aumentar la dosis de metformina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.', 'text': 'Iniciar insulina', 'is_correct': True},\n",
       "   {'letter': 'd.', 'text': 'Iniciar hemodiálisis', 'is_correct': False},\n",
       "   {'letter': 'e.',\n",
       "    'text': 'Hacer énfasis en el seguimiento de la dieta y correcto uso de los hipoglicemiantes orales y controlar con',\n",
       "    'is_correct': False}],\n",
       "  'correct_answer': 'c. Iniciar insulina',\n",
       "  'explanation': 'Por tener una IRC, con creatinina mayor a 1,4, están contraindicados los HGO habituales (metformina y glibenclamida) y de elección es la insulina, siendo una opción los agonistas GLP-1 como la semaglutida y liraglutide. En este caso, además tiene proteinuria, por lo que se debe iniciar un IECA. La HbA1c está en 8,5%, lo que muestra un mal control metabólico, pero per sé no indica la insulina. En cambio, si fuera mayor o igual a 9%, sería indicación de insulina. Al iniciar la insulina NPH se suele mantener la metformina y se puede mantener o suspender la glibenclamida, pero en este caso se debe suspender la metformina, por tener IRC (nefropatía diabética establecida).',\n",
       "  'right_answer_text': 'La respuesta correcta es: Iniciar insulina',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '7',\n",
       "  'question_number': '7',\n",
       "  'topic': 'Un paciente de 65 años, diabético tipo 2, de larga data, con tratamiento irregular con metformina y ',\n",
       "  'question_text': 'Un paciente de 65 años, diabético tipo 2, de larga data, con tratamiento irregular con metformina y glibenclamida consulta por dolor intenso de la extremidad inferior izquierda, de tipo neurálgico, que recorre el dermatomo L4. Al examen físico se observa enflaquecido, con disminución de la sensibilidad distal y sin alteraciones motoras. La hemoglobina glicosilada resulta 9,9%. La conducta más adecuada es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Reforzar el tratamiento con hipoglicemiantes orales y controlar en 3 meses',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Suspender la glibenclamida y agregar insulina NPH nocturna',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Indicar zapatos adecuados y revisión diaria de los pies y regularizar el tratamiento con hipoglicemiantes orales',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Indicar un plan de ejercicios, reforzar la adhesión al tratamiento y controlar en 7 días',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.',\n",
       "    'text': 'Hospitalizar, iniciar insulinoterapia y venlafaxina oral',\n",
       "    'is_correct': True}],\n",
       "  'correct_answer': 'e. Hospitalizar, iniciar insulinoterapia y venlafaxina oral',\n",
       "  'explanation': 'Tiene una neuropatía diabética dolorosa, por lo que se trata con moduladores del dolor (antidepresivos duales: venlafaxina, duloxetina; fármacos gaba: gabapentina, pregabalina; o antidepresivos tricíclicos) e insulina (en especial cuando hay dolor y atrofia, en relación a las neuropatías). Además, por la HbA1c mayor a 9%, también está indicada la insulina. Probablemente se mantendrá la metformina. La hospitalización es discutible, pero se recomienda iniciar la insulinoterapia con una cuidadosa observación, para evitar hipoglicemias y asegurar una buena aplicación del tratamiento, por parte del paciente.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Hospitalizar, iniciar insulinoterapia y venlafaxina oral',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '8',\n",
       "  'question_number': '8',\n",
       "  'topic': 'Un paciente diabético tipo 2, acude a control ambulatorio',\n",
       "  'question_text': 'Un paciente diabético tipo 2, acude a control ambulatorio. Actualmente está en tratamiento con metformina 850 mg cada 8 horas, aspirina 100 mg al día y enalapril 20 mg c/12 horas. En sus exámenes destaca creatinina 2,0 mg/dl, proteinuria 350 mg/dl, glicemia de ayuno: 140 mg/dl y HbA1c: 8,5%. La conducta más adecuada es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Mantener el tratamiento y controlar en 3 meses',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Aumentar la dosis de metformina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Agregar glibenclamida al tratamiento',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Reemplazar la metformina común por metformina de liberación prolongada',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.', 'text': 'Iniciar insulina', 'is_correct': True}],\n",
       "  'correct_answer': 'e. Iniciar insulina',\n",
       "  'explanation': 'Nuevamente, por la IRC (creatinina mayor a 1,4), están contraindicados los HGO e indicada la insulina o los GLP-1. La proteinuria también está elevada (mayor a 300 mg/día), por lo que hay que iniciar un IECA, pero, en este caso, el clearence de creatinina está muy bajo y es posible que estén contraindicados los más usados y, en su lugar, se puede buscar un IECA con perfil renal más seguro o con una dosis baja, siguiendo muy de cerca el empeoramiento de la función renal y la aparición de hiperkalemia.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Iniciar insulina',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '9',\n",
       "  'question_number': '9',\n",
       "  'topic': 'Un paciente de 60 años, hipertenso, sufrió un infarto de pared anterior hace 1 año, el que fue manej',\n",
       "  'question_text': 'Un paciente de 60 años, hipertenso, sufrió un infarto de pared anterior hace 1 año, el que fue manejado con angioplastia. Acude a control, con un perfil lipídico, con los siguientes valores: colesterol total: 220 mg/dl, colesterol HDL: 40 mg/dl, colesterol LDL: 160 mg/dl, triglicéridos: 100 mg/dl. Refiere no tomar ningún medicamento hipolipemiante ni seguir ninguna dieta. La conducta más adecuada para el manejo de sus lípidos es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Observar evolución',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Indicar dieta baja en grasas trans, grasas saturadas y colesterol y controlar en 3 meses',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Indicar dieta e iniciar una estatina',\n",
       "    'is_correct': True},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Indicar dieta e iniciar un fibrato',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.',\n",
       "    'text': 'Indicar dieta e iniciar una estatina, asociada a un fibrato',\n",
       "    'is_correct': False}],\n",
       "  'correct_answer': 'c. Indicar dieta e iniciar una estatina',\n",
       "  'explanation': 'Por tener un IAM previo, su riesgo cardiovascular es máximo y por tanto el objetivo de LDL es menor a 70 mg/dl. Además, tiene HDL bajo (menor a 40), pero TG normales (menores a 150). Por tanto, la prioridad será el manejo del LDL, lo que requiere una estatina, por tener riesgo cardiovascular máximo. Además, debe quedar con aspirina y evaluar la introducción de múltiples fármacos para su cardiopatía coronaria (IECAs, betabloqueantes, por ejemplo).',\n",
       "  'right_answer_text': 'La respuesta correcta es: Indicar dieta e iniciar una estatina',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '10',\n",
       "  'question_number': '10',\n",
       "  'topic': 'Una paciente ha presentado 5 hipoglicemias, las que han requerido hospitalización en varias oportuni',\n",
       "  'question_text': 'Una paciente ha presentado 5 hipoglicemias, las que han requerido hospitalización en varias oportunidades. Niega antecedentes de importancia, pero los familiares sospechan que está autoinduciéndose los síntomas. En la última hospitalización se realiza estudio que revela insulina de 55 UI/L y péptico C elevado. ¿Cuál de los siguientes diagnósticos es más probable?',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Hipoglicemia facticia por insulina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Hipoglicemia facticia por metformina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Hipoglicemia facticia por glibenclamida',\n",
       "    'is_correct': True},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Hipoglicemia facticia por pioglitazona',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.', 'text': 'Hipoglicemia de ayuno', 'is_correct': False}],\n",
       "  'correct_answer': 'c. Hipoglicemia facticia por glibenclamida',\n",
       "  'explanation': 'Que el péptido C esté elevado significa que su páncreas está produciendo mucha insulina (la que está elevada también). La glibenclamida es una sulfonilúrea, por lo que aumenta la secreción de insulina (secretagogo), lo que es compatible con el cuadro. La insulina exógena tendría insulina alta, pero péptido C bajo. La metformina y la pioglitazona suelen no producir hipoglicemias, porque solo disminuyen la resistencia a la insulina. De todos modos, en caso de producirla, sería con insulina y péptido C bajos, ya que actúan aumentando el efecto de la insulina y no la cantidad de insulina. Las hipoglicemias de ayuno, también son con pépyido C e insulina bajos.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Hipoglicemia facticia por glibenclamida',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '11',\n",
       "  'question_number': '11',\n",
       "  'topic': 'Un niño de 8 años presenta un cuadro de astenia y baja de peso, de cerca de 2 semanas de evolución',\n",
       "  'question_text': 'Un niño de 8 años presenta un cuadro de astenia y baja de peso, de cerca de 2 semanas de evolución. Además, presenta poliuria y polidipsia importante. Se solicita una glicemia de ayuno, que resulta 220 mg/dl. La conducta más adecuada es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Repetir la glicemia en 7 días',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Iniciar insulina NPH en dos dosis',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Iniciar insulina es esquema intensificado, con una dosis de insulina ultralenta (glargina) más refuerzos con insulina cristalina',\n",
       "    'is_correct': True},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Solicitar test de tolerancia a la glucosa',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.',\n",
       "    'text': 'Iniciar dieta, ejercicio y metformina',\n",
       "    'is_correct': False}],\n",
       "  'correct_answer': 'c. Iniciar insulina es esquema intensificado, con una dosis de insulina ultralenta (glargina) más refuerzos con insulina cristalina',\n",
       "  'explanation': 'El diagnóstico es una diabetes mellitus, ya que cumple con el criterio de una glicemia mayor o igual a 200 (ya sea de ayuno o no), más síntomas de diabetes (poliuria, polidipsia, baja de peso). Por se un niño, se asume que la diabetes es tipo 1, es decir autoinmune y se inicia el tratamiento con insulina en esquema intensificado, que es el tratamiento de elección para este tipo de diabetes (y también para la diabetes LADA del adulto). Si hubiese sido en un adulto, también estaría indicado el inicio de insulina, ya que la presencia de síntomas de diabetes obliga a estabilizar con insulina a los pacientes con DM2 también, aunque no necesariamente en esquema intensificado y se podría tratar con insulina NPH sola.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Iniciar insulina es esquema intensificado, con una dosis de insulina ultralenta (glargina) más refuerzos con insulina cristalina',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '12',\n",
       "  'question_number': '12',\n",
       "  'topic': 'Un paciente de 56 años acude a control con el siguiente perfil lipídico: colesterol total: 348 mg/dl',\n",
       "  'question_text': 'Un paciente de 56 años acude a control con el siguiente perfil lipídico: colesterol total: 348 mg/dl, colesterol HDL: 30 mg/dl, colesterol LDL: 190 mg/dl, triglicéridos: 640 mg/dl. La conducta más adecuada es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Iniciar dieta y ejercicio',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Iniciar dieta y una estatina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.', 'text': 'Iniciar dieta y un fibrato', 'is_correct': True},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Iniciar dieta y una asociación entre una estatina y un fibrato',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.',\n",
       "    'text': 'Hospitalizar e iniciar insulina cristalina',\n",
       "    'is_correct': False}],\n",
       "  'correct_answer': 'c. Iniciar dieta y un fibrato',\n",
       "  'explanation': 'Tiene LDL elevado, TG elevados y HDL bajo. Por estar los TG sobre 500, pasan a ser la prioridad y se deben tratar con un fibrato. Recordar que los médicos generales nunca deben mezclar fibratos con estatinas, ya que por un lado se dispara el riesgo de rabdomiólisis y por otro lado, todos los hipolipemiantes sirven en cierta medida para el tratamiento de las tres dislipidemias. Solo los especialistas pueden, en casos seleccionados, mezclar estatinas con fenofibrato (no con gemfibrozilo).',\n",
       "  'right_answer_text': 'La respuesta correcta es: Iniciar dieta y un fibrato',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '13',\n",
       "  'question_number': '13',\n",
       "  'topic': 'Un paciente de 45 años diabético, tipo 2, en tratamiento con metformina en dosis máxima, acude a con',\n",
       "  'question_text': 'Un paciente de 45 años diabético, tipo 2, en tratamiento con metformina en dosis máxima, acude a control con los siguientes registros de glicemias promedio: Además presenta una hemoglobina glicosilada de 7,5%. La conducta más adecuada es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Agregar glibenclamida y mantener la metformina',\n",
       "    'is_correct': True},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Iniciar glibenclamida y suspender la metformina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Iniciar insulina NPH matinal',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Iniciar insulina NPH nocturna',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.',\n",
       "    'text': 'Iniciar insulina cristalina junto con las 3 comidas',\n",
       "    'is_correct': False}],\n",
       "  'correct_answer': 'a. Agregar glibenclamida y mantener la metformina',\n",
       "  'explanation': 'Su control metabólico es insuficiente, ya que la HbA1c está mayor a 7% y tiene varias glicemias sobre los niveles recomendados (preprandiales < 130-100 y posprandiales < 180-130, según qué tan estricto se pretende ser). Lo más importante es la hemoglobina glicosilada. No tiene ninguna indicación de insulina, ni contraindicación de los hipoglicemiantes orales. Además, está solo con metformina en dosis máximas, por lo que es posible agregar glibenclamida y, si está disponible, otro hipoglicemiante más seguro (GLP-1 como la semaglutida, SGLT-2 como la empaglifozina o DPP-4 como la sitagliptina). En todo caso, por ser joven y sin comorbilidad, la glibenclamida no tiene mayores contraindicaciones. Si hubiese tenido más de 75 años, estaría bien controlado (objetivo HbA1c <8%) y se debería mantener el tratamiento; y si, además de 75 años, hubiese tenido la hemoglobina sobre 8%, no se debería iniciar glibenclamida, sino otro hipoglicemiante más seguro, con menor riesgo de hipoglicemia, como la sitagliptina o el liraglutide.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Agregar glibenclamida y mantener la metformina',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '14',\n",
       "  'question_number': '14',\n",
       "  'topic': 'Un paciente diabético tipo 2, en tratamiento con dieta, el que sigue de manera irregular, consulta p',\n",
       "  'question_text': 'Un paciente diabético tipo 2, en tratamiento con dieta, el que sigue de manera irregular, consulta por dolor en ambas extremidades inferiores, que es de tipo urente y que es especialmente intenso en la noche. Al examen presenta alodinia, sin focalidad neurológica, ni lesiones en la piel. La conducta más adecuada es:',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Iniciar metformina y AINEs',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Iniciar glibenclamida y clomipramina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Iniciar metformina y gabapentina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'd.',\n",
       "    'text': 'Iniciar insulina y pregabalina',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'e.', 'text': 'Iniciar insulina y AINEs', 'is_correct': False}],\n",
       "  'correct_answer': None,\n",
       "  'explanation': 'Tiene una neuropatía diabética dolorosa, por lo que se trata con moduladores del dolor como la pregabalina, gabapentina, antidepresivos duales (venlafaxina o duloxetina) o antidepresivos tricíclicos (clomipramina, Imipramina y amitriptilina, aunque se usan menos por sus efectos adversos), más insulina. Recordemos que el diagnóstico de la neuropatía dolorosa es clínico (dolor neuropático, urente, con alodinia). La gabapentina y la pregabalina son útiles, en particular en adultos mayores, en que están contraindicados los ADTC, que son fármacos que producen efectos adversos con mayor frecuencia. Sin embargo, los hipogicemiantes orales no suelen ser suficientes y solo la insulina acelera la desaparición del dolor.',\n",
       "  'right_answer_text': 'La respuesta correcta es: Iniciar insulina y pregabalina',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'},\n",
       " {'question_id': '15',\n",
       "  'question_number': '15',\n",
       "  'topic': 'Un paciente de 50 años, diabético tipo 2, en tratamiento con metformina 500 mg cada 8 horas, acude a',\n",
       "  'question_text': 'Un paciente de 50 años, diabético tipo 2, en tratamiento con metformina 500 mg cada 8 horas, acude a control. Trae una hemoglobina glicosilada de 10,3% y una proteinuria de 24 horas en 500 mg/dl. ¿Cuál es la conducta más adecuada para el control metabólico de este paciente?',\n",
       "  'answer_options': [{'letter': 'a.',\n",
       "    'text': 'Mantener la metformina y hacer hincapié en el cumplimiento de la dieta',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'b.',\n",
       "    'text': 'Aumentar la dosis de metformina a 850 mg cada 8 horas y agregar enalapril',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'c.',\n",
       "    'text': 'Agregar glibenclamida 5 mg cada 12 horas',\n",
       "    'is_correct': False},\n",
       "   {'letter': 'd.', 'text': 'Agregar sitagliptina', 'is_correct': False},\n",
       "   {'letter': 'e.',\n",
       "    'text': 'Iniciar insulina y valsartán',\n",
       "    'is_correct': True}],\n",
       "  'correct_answer': 'e. Iniciar insulina y valsartán',\n",
       "  'explanation': 'Tiene una hemoglobina glicosilada mayor o igual a 9%, por lo que tiene indicación de iniciar con insulina NPH nocturna (10 UI por lo general, aunque hay distintos esquemas). La metformina se recomienda mantener, porque no hay insuficiencia renal o daño hepático que la contraindique y porque está demostrado que el control metabólico es mejor al mantener los hipoglicemiantes orales. Además, por la proteinuria, se asume que hay nefropatía, por lo que deberá iniciar un IECA (ejemplo enalapril), siendo también aceptable indicar un ARA2 (valsartán).',\n",
       "  'right_answer_text': 'La respuesta correcta es: Iniciar insulina y valsartán',\n",
       "  'source_exam': 'GUEVARA - Diabetes Quiz'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "101715cc879e2f59"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-19T19:45:07.006405Z",
     "start_time": "2025-10-19T19:45:06.283644Z"
    }
   },
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "path = r\"C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\\view-source_https___cursosonline.doctorguevara.cl_mod_quiz_review.php_attempt=1263771&cmid=125317.html\"\n",
    "\n",
    "# Read the HTML\n",
    "print(\"Reading HTML file...\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "print(f\"File size: {len(html_content)} characters\\n\")\n",
    "\n",
    "# Parse with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Debug: Let's see what classes are available\n",
    "print(\"=\" * 80)\n",
    "print(\"DEBUGGING: Finding all div classes\")\n",
    "print(\"=\" * 80)\n",
    "all_divs = soup.find_all(\"div\")\n",
    "classes_found = set()\n",
    "for div in all_divs:\n",
    "    if div.get(\"class\"):\n",
    "        classes_found.update(div.get(\"class\"))\n",
    "\n",
    "print(f\"Total divs found: {len(all_divs)}\")\n",
    "print(f\"Unique classes found: {len(classes_found)}\")\n",
    "print(\"\\nClasses containing 'que' or 'question':\")\n",
    "for cls in sorted(classes_found):\n",
    "    if \"que\" in cls.lower() or \"question\" in cls.lower():\n",
    "        print(f\"  - {cls}\")\n",
    "\n",
    "# Try to find questions with different selectors\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRYING DIFFERENT SELECTORS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Method 1: Look for divs with id starting with \"question\"\n",
    "questions_by_id = soup.find_all(\"div\", id=lambda x: x and x.startswith(\"question\"))\n",
    "print(f\"\\nMethod 1 - Divs with id starting with 'question': {len(questions_by_id)}\")\n",
    "\n",
    "# Method 2: Look for class 'que'\n",
    "questions_by_class = soup.find_all(\"div\", class_=\"que\")\n",
    "print(f\"Method 2 - Divs with class 'que': {len(questions_by_class)}\")\n",
    "\n",
    "# Method 3: Look for specific class combinations\n",
    "questions_multichoice = soup.find_all(\"div\", class_=\"que multichoice deferredfeedback\")\n",
    "print(f\"Method 3 - Divs with 'que multichoice deferredfeedback': {len(questions_multichoice)}\")\n",
    "\n",
    "# Method 4: Look for question tags\n",
    "h3_tags = soup.find_all(\"h3\", class_=\"no\")\n",
    "print(f\"Method 4 - H3 tags with class 'no': {len(h3_tags)}\")\n",
    "\n",
    "# Let's examine the first question in detail\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMINING FIRST QUESTION STRUCTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if questions_by_id:\n",
    "    first_q = questions_by_id[0]\n",
    "    print(f\"\\nFirst question ID: {first_q.get('id')}\")\n",
    "    print(f\"First question classes: {first_q.get('class')}\")\n",
    "\n",
    "    # Check for question text\n",
    "    qtext = first_q.find(\"div\", class_=\"qtext\")\n",
    "    if qtext:\n",
    "        print(f\"\\nQuestion text found (first 200 chars):\")\n",
    "        print(qtext.get_text(strip=True)[:200])\n",
    "\n",
    "    # Check for answers\n",
    "    answers = first_q.find_all(\"div\", class_=\"r0\") + first_q.find_all(\"div\", class_=\"r1\")\n",
    "    print(f\"\\nAnswer divs found (r0/r1): {len(answers)}\")\n",
    "\n",
    "    # Check for correct answer\n",
    "    correct = first_q.find(\"div\", class_=\"correct\")\n",
    "    print(f\"Correct answer div found: {correct is not None}\")\n",
    "\n",
    "    # Print partial structure\n",
    "    print(\"\\n--- Partial HTML structure of first question ---\")\n",
    "    print(str(first_q)[:1000])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NOW ATTEMPTING FULL EXTRACTION\")\n",
    "print(\"=\" * 80)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading HTML file...\n",
      "File size: 1074933 characters\n",
      "\n",
      "================================================================================\n",
      "DEBUGGING: Finding all div classes\n",
      "================================================================================\n",
      "Total divs found: 1\n",
      "Unique classes found: 1\n",
      "\n",
      "Classes containing 'que' or 'question':\n",
      "\n",
      "================================================================================\n",
      "TRYING DIFFERENT SELECTORS\n",
      "================================================================================\n",
      "\n",
      "Method 1 - Divs with id starting with 'question': 0\n",
      "Method 2 - Divs with class 'que': 0\n",
      "Method 3 - Divs with 'que multichoice deferredfeedback': 0\n",
      "Method 4 - H3 tags with class 'no': 0\n",
      "\n",
      "================================================================================\n",
      "EXAMINING FIRST QUESTION STRUCTURE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "NOW ATTEMPTING FULL EXTRACTION\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T19:45:44.448282Z",
     "start_time": "2025-10-19T19:45:43.667562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "path = r\"C:\\Users\\vales\\DataspellProjects\\keuna\\EUNACOM\\ENSAYOS\\GUEVARA\\view-source_https___cursosonline.doctorguevara.cl_mod_quiz_review.php_attempt=1263771&cmid=125317.html\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Find questions (adjust based on debugging output)\n",
    "questions = soup.find_all(\"div\", id=lambda x: x and x.startswith(\"question\"))\n",
    "\n",
    "print(f\"Found {len(questions)} questions\\n\")\n",
    "\n",
    "# Extract data\n",
    "data = []\n",
    "\n",
    "for question in questions:\n",
    "    try:\n",
    "        # Question number\n",
    "        qno = question.find(\"span\", class_=\"qno\")\n",
    "        q_number = qno.get_text(strip=True) if qno else \"N/A\"\n",
    "\n",
    "        # Question text\n",
    "        qtext = question.find(\"div\", class_=\"qtext\")\n",
    "        q_text = qtext.get_text(strip=True, separator=\" \") if qtext else \"N/A\"\n",
    "\n",
    "        # State (correct/incorrect)\n",
    "        state = question.find(\"div\", class_=\"state\")\n",
    "        q_state = state.get_text(strip=True) if state else \"N/A\"\n",
    "\n",
    "        # Find all answer options\n",
    "        answer_containers = question.find_all(\"div\", class_=[\"r0\", \"r1\"])\n",
    "\n",
    "        correct_answer = None\n",
    "        all_answers = []\n",
    "\n",
    "        for container in answer_containers:\n",
    "            # Get answer letter and text\n",
    "            answer_label = container.find(\"div\", class_=\"d-flex\")\n",
    "            if answer_label:\n",
    "                letter_span = answer_label.find(\"span\", class_=\"answernumber\")\n",
    "                text_div = answer_label.find(\"div\", class_=\"flex-fill\")\n",
    "\n",
    "                if letter_span and text_div:\n",
    "                    letter = letter_span.get_text(strip=True)\n",
    "                    text = text_div.get_text(strip=True)\n",
    "\n",
    "                    all_answers.append(f\"{letter} {text}\")\n",
    "\n",
    "                    # Check if this is correct\n",
    "                    if \"correct\" in container.get(\"class\", []):\n",
    "                        correct_answer = f\"{letter} {text}\"\n",
    "\n",
    "        # Feedback\n",
    "        feedback = question.find(\"div\", class_=\"generalfeedback\")\n",
    "        feedback_text = feedback.get_text(strip=True) if feedback else \"\"\n",
    "\n",
    "        data.append(\n",
    "            {\n",
    "                \"Question_Number\": q_number,\n",
    "                \"Status\": q_state,\n",
    "                \"Question\": q_text,\n",
    "                \"Correct_Answer\": correct_answer,\n",
    "                \"All_Answers\": \" | \".join(all_answers),\n",
    "                \"Feedback\": feedback_text,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"✓ Extracted Q{q_number}: {q_state}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing question: {e}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXTRACTED DATA\")\n",
    "print(\"=\" * 80)\n",
    "print(df[[\"Question_Number\", \"Status\", \"Correct_Answer\"]].to_string())\n",
    "\n",
    "# Save to Excel\n",
    "output_excel = \"quiz_results.xlsx\"\n",
    "df.to_excel(output_excel, index=False, engine=\"openpyxl\")\n",
    "print(f\"\\n✓ Saved to {output_excel}\")\n",
    "\n",
    "# Save to CSV\n",
    "output_csv = \"quiz_results.csv\"\n",
    "df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✓ Saved to {output_csv}\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(f\"Total questions: {len(df)}\")\n",
    "print(f\"Correct: {len(df[df['Status'] == 'Correcta'])}\")\n",
    "print(f\"Incorrect: {len(df[df['Status'] == 'Incorrecta'])}\")"
   ],
   "id": "f48f57dbe47d1a8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 questions\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXTRACTED DATA\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Question_Number', 'Status', 'Correct_Answer'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 81\u001B[39m\n\u001B[32m     79\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mEXTRACTED DATA\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     80\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m*\u001B[32m80\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m81\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mQuestion_Number\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mStatus\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mCorrect_Answer\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m.to_string())\n\u001B[32m     83\u001B[39m \u001B[38;5;66;03m# Save to Excel\u001B[39;00m\n\u001B[32m     84\u001B[39m output_excel = \u001B[33m'\u001B[39m\u001B[33mquiz_results.xlsx\u001B[39m\u001B[33m'\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\DataspellProjects\\kverse\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4111\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[32m   4112\u001B[39m         key = \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[32m-> \u001B[39m\u001B[32m4113\u001B[39m     indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcolumns\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[32m1\u001B[39m]\n\u001B[32m   4115\u001B[39m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[32m   4116\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) == \u001B[38;5;28mbool\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\DataspellProjects\\kverse\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001B[39m, in \u001B[36mIndex._get_indexer_strict\u001B[39m\u001B[34m(self, key, axis_name)\u001B[39m\n\u001B[32m   6209\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   6210\u001B[39m     keyarr, indexer, new_indexer = \u001B[38;5;28mself\u001B[39m._reindex_non_unique(keyarr)\n\u001B[32m-> \u001B[39m\u001B[32m6212\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   6214\u001B[39m keyarr = \u001B[38;5;28mself\u001B[39m.take(indexer)\n\u001B[32m   6215\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[32m   6216\u001B[39m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\DataspellProjects\\kverse\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001B[39m, in \u001B[36mIndex._raise_if_missing\u001B[39m\u001B[34m(self, key, indexer, axis_name)\u001B[39m\n\u001B[32m   6259\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m nmissing:\n\u001B[32m   6260\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m nmissing == \u001B[38;5;28mlen\u001B[39m(indexer):\n\u001B[32m-> \u001B[39m\u001B[32m6261\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m]\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   6263\u001B[39m     not_found = \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask.nonzero()[\u001B[32m0\u001B[39m]].unique())\n\u001B[32m   6264\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m not in index\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mKeyError\u001B[39m: \"None of [Index(['Question_Number', 'Status', 'Correct_Answer'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f9f1751f2752d813"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
